{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 14: MCP-Powered X Post Summarizer\n",
    "\n",
    "## Building a LangGraph Agent with GitHub MCP Tools, X API Tools, and Memory\n",
    "\n",
    "## Learning Objectives:\n",
    "\n",
    "- **Ingest MCP servers as LangGraph tools** using `langchain-mcp-adapters` to connect to the GitHub MCP Server and use its tools programmatically\n",
    "- **Wrap the X (Twitter) API as a LangChain tool** using the `@tool` decorator so a LangGraph agent can search and retrieve public posts\n",
    "- **Build a LangGraph agent with memory** that combines MCP-sourced tools and custom tools, using `MemorySaver` for short-term conversational memory\n",
    "- **Orchestrate a full workflow through the agent** â€” search X posts, generate summaries, create a GitHub repo, commit files, branch, and open a PR â€” all via natural language\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this notebook, you will build a **LangGraph ReAct agent** that has access to two categories of tools:\n",
    "\n",
    "1. **GitHub MCP tools** â€” loaded from the official GitHub MCP Server via `langchain-mcp-adapters`. These replace manual `git` commands with tool calls the agent can invoke (create repos, commit files, create branches, open PRs).\n",
    "2. **X API tools** â€” custom Python functions wrapped with the `@tool` decorator that call the X API v2 directly to search and retrieve posts.\n",
    "\n",
    "The agent uses **`MemorySaver`** for short-term memory so it can maintain context across multi-step workflows within a conversation thread.\n",
    "\n",
    "There will be one breakout room with two phases:\n",
    "\n",
    "- ðŸ¤ Phase 1: Setup, Tools & Agent Construction\n",
    "  - Task 1: Dependencies & Environment\n",
    "  - Task 2: X API as LangChain Tools\n",
    "  - Task 3: Connect to GitHub MCP Server & Load Tools\n",
    "  - Task 4: Build the LangGraph Agent with Memory\n",
    "  - Task 5: Test the Agent â€” Search & Summarize X Posts\n",
    "  - Activity #1: Extend the Agent with a Custom X API Tool\n",
    "- ðŸ¤ Phase 2: MCP Workflow Through the Agent\n",
    "  - Task 6: Create a GitHub Repository\n",
    "  - Task 7: Commit the Summary\n",
    "  - Task 8: Create a Feature Branch & Add Metadata\n",
    "  - Task 9: Open a Pull Request\n",
    "  - Task 10: Commit the X API Script\n",
    "  - Task 11: Update the README\n",
    "  - Activity #1: Multi-Account Comparison Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ðŸ¤ Breakout Room \n",
    "## Setup, Tools & Agent Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Dependencies & Environment\n",
    "\n",
    "We need:\n",
    "- `langchain-mcp-adapters` to connect to MCP servers and convert their tools into LangChain tools\n",
    "- `langgraph` for our agent graph with memory\n",
    "- `langchain-openai` for our LLM\n",
    "- `requests` for the X API calls\n",
    "- `nest-asyncio` for async MCP operations inside Jupyter\n",
    "\n",
    "> NOTE: Create a `.env` file in this directory with `X_BEARER_TOKEN`, `OPENAI_API_KEY`, and `GITHUB_PAT` before running.\n",
    "> \n",
    "> Setup references:\n",
    "> - GitHub fine-grained PAT guide: [Creating a personal access token](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens#creating-a-fine-grained-personal-access-token)\n",
    "> - X API Bearer Token setup: [X Developer Portal](https://developer.x.com/en/portal/dashboard) and [X API access tiers](https://developer.x.com/en/products/twitter-api)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "if not os.environ.get(\"X_BEARER_TOKEN\"):\n",
    "    os.environ[\"X_BEARER_TOKEN\"] = getpass.getpass(\"Enter your X Bearer Token:\")\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API Key:\")\n",
    "\n",
    "if not os.environ.get(\"GITHUB_PAT\"):\n",
    "    os.environ[\"GITHUB_PAT\"] = getpass.getpass(\"Enter your GitHub PAT:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()  # Required for async operations in Jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Your Credentials\n",
    "\n",
    "**GitHub PAT (fine-grained):**\n",
    "1. Open [GitHub Personal Access Tokens (fine-grained)](https://github.com/settings/personal-access-tokens/new).\n",
    "2. Follow [GitHub's PAT setup guide](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens#creating-a-fine-grained-personal-access-token).\n",
    "3. Set repository permissions to at least:\n",
    "   - `Contents`: Read and write\n",
    "   - `Pull requests`: Read and write\n",
    "   - `Metadata`: Read-only\n",
    "\n",
    "**X Bearer Token:**\n",
    "1. Open the [X Developer Portal](https://developer.x.com/en/portal/dashboard).\n",
    "2. Create/select a Project + App, then go to **Keys and Tokens** to generate a Bearer Token.\n",
    "3. Confirm your plan supports the recent search endpoint (`GET /2/tweets/search/recent`) from the [X API product page](https://developer.x.com/en/products/twitter-api).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "\n",
    "# Test the connection\n",
    "response = llm.invoke(\"Say 'MCP agent ready!' in exactly those words.\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: X API as LangChain Tools\n",
    "\n",
    "Instead of relying on a community-built MCP server for X, we'll call the **X API v2** directly and wrap our functions with the `@tool` decorator. This makes them available to our LangGraph agent as callable tools â€” just like the MCP tools will be.\n",
    "\n",
    "This is a key architectural decision: **not everything needs to be an MCP server**. Wrapping a simple API call as a `@tool` is often simpler and more transparent.\n",
    "\n",
    "**ðŸ“š Documentation:**\n",
    "- [LangChain Tools Conceptual Guide](https://python.langchain.com/docs/concepts/tools/)\n",
    "- [X API v2 Documentation](https://developer.x.com/en/docs/x-api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "BEARER_TOKEN = os.environ.get(\"X_BEARER_TOKEN\")\n",
    "\n",
    "\n",
    "@tool\n",
    "def search_recent_posts(query: str, max_results: int = 20) -> str:\n",
    "    \"\"\"Search recent X/Twitter posts using the v2 API.\n",
    "    Returns posts from the last 7 days matching the query.\n",
    "    Use this for keyword searches, hashtag searches, or general topic searches.\n",
    "\n",
    "    Args:\n",
    "        query: The search query (e.g., 'AI safety', '#machinelearning', 'from:AndrewYNg')\n",
    "        max_results: Number of results to return (10-100, default 20)\n",
    "    \"\"\"\n",
    "    url = \"https://api.x.com/2/tweets/search/recent\"\n",
    "    headers = {\"Authorization\": f\"Bearer {BEARER_TOKEN}\"}\n",
    "    params = {\n",
    "        \"query\": query,\n",
    "        \"max_results\": min(max(max_results, 10), 100),\n",
    "        \"tweet.fields\": \"created_at,public_metrics,author_id,text\",\n",
    "        \"expansions\": \"author_id\",\n",
    "        \"user.fields\": \"name,username\",\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "\n",
    "    tweets = data.get(\"data\", [])\n",
    "    if not tweets:\n",
    "        return \"No posts found for this query.\"\n",
    "\n",
    "    result_lines = [f\"Found {len(tweets)} posts:\\n\"]\n",
    "    for t in tweets:\n",
    "        metrics = t.get(\"public_metrics\", {})\n",
    "        result_lines.append(\n",
    "            f\"[{t.get('created_at', 'unknown')[:10]}] \"\n",
    "            f\"{t['text'][:200]}\\n\"\n",
    "            f\"  Likes: {metrics.get('like_count', 0)} | \"\n",
    "            f\"Retweets: {metrics.get('retweet_count', 0)}\"\n",
    "        )\n",
    "    return \"\\n\\n\".join(result_lines)\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_user_posts(username: str, max_results: int = 20) -> str:\n",
    "    \"\"\"Get recent original posts (no retweets) from a specific X/Twitter user.\n",
    "    Use this when you want to see what a specific account has been posting.\n",
    "\n",
    "    Args:\n",
    "        username: The X/Twitter handle without the @ sign (e.g., 'AndrewYNg')\n",
    "        max_results: Number of results to return (10-100, default 20)\n",
    "    \"\"\"\n",
    "    query = f\"from:{username} -is:retweet\"\n",
    "    return search_recent_posts.invoke({\"query\": query, \"max_results\": max_results})\n",
    "\n",
    "\n",
    "x_api_tools = [search_recent_posts, get_user_posts]\n",
    "print(f\"Created {len(x_api_tools)} X API tools: {[t.name for t in x_api_tools]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify our X API tools work before wiring them into the agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick test â€” fetch recent posts from a public account\n",
    "result = get_user_posts.invoke({\"username\": \"llm_wizard\", \"max_results\": 10})\n",
    "print(result[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Connect to GitHub MCP Server & Load Tools\n",
    "\n",
    "Now we'll connect to the **GitHub MCP Server** â€” an official, GitHub-maintained MCP server that gives agents the ability to manage repositories, issues, pull requests, and more.\n",
    "\n",
    "We use `langchain-mcp-adapters` to:\n",
    "1. Connect to the remote GitHub MCP server over HTTP\n",
    "2. Automatically convert all MCP tools into LangChain-compatible tools\n",
    "\n",
    "This is the key MCP integration point â€” instead of writing custom GitHub API wrappers, we get a full set of tools for free just by connecting to the MCP server.\n",
    "\n",
    "**ðŸ“š Documentation:**\n",
    "- [langchain-mcp-adapters](https://github.com/langchain-ai/langchain-mcp-adapters)\n",
    "- [GitHub MCP Server](https://github.com/github/github-mcp-server)\n",
    "- [Model Context Protocol Specification](https://modelcontextprotocol.io/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "\n",
    "# Connect to the GitHub MCP server using Streamable HTTP transport\n",
    "# The server exposes GitHub operations as MCP tools that our agent can call\n",
    "mcp_client = MultiServerMCPClient(\n",
    "    {\n",
    "        \"github\": {\n",
    "            \"transport\": \"http\",\n",
    "            \"url\": \"https://api.githubcopilot.com/mcp/\",\n",
    "            \"headers\": {\n",
    "                \"Authorization\": f\"Bearer {os.environ['GITHUB_PAT']}\",\n",
    "            },\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "# Load all tools from the MCP server\n",
    "github_mcp_tools = await mcp_client.get_tools()\n",
    "\n",
    "print(f\"Loaded {len(github_mcp_tools)} GitHub MCP tools:\\n\")\n",
    "for t in github_mcp_tools:\n",
    "    print(f\"  - {t.name}: {t.description[:80]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key GitHub MCP Tools\n",
    "\n",
    "The MCP server exposes many tools, but the key ones we'll use are:\n",
    "\n",
    "| MCP Tool | Replaces (Git CLI) | What It Does |\n",
    "|---|---|---|\n",
    "| `create_repository` | `git init` + GitHub UI | Creates a new repo on your account |\n",
    "| `create_or_update_file` | `git add` + `git commit` + `git push` | Commits a file directly to a branch |\n",
    "| `create_branch` | `git checkout -b` | Creates a new branch |\n",
    "| `create_pull_request` | `gh pr create` | Opens a PR from one branch to another |\n",
    "| `search_repositories` | `gh repo list` | Searches across your repos |\n",
    "| `get_file_contents` | `git show` / `cat` | Reads a file from a repo |\n",
    "| `list_commits` | `git log` | Shows commit history |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Build the LangGraph Agent with Memory\n",
    "\n",
    "Now we combine **both tool sets** into a single LangGraph agent:\n",
    "- **X API tools** â€” custom `@tool` functions for searching posts\n",
    "- **GitHub MCP tools** â€” loaded from the MCP server via `langchain-mcp-adapters`\n",
    "\n",
    "We add **`MemorySaver`** for short-term memory so the agent remembers context across the multi-step workflow (e.g., it fetches posts in one turn, summarizes them in the next, and commits the summary in a third).\n",
    "\n",
    "The architecture follows the standard LangGraph ReAct pattern from Sessions 4-6:\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  START   â”‚â”€â”€â”€â”€â–¶â”‚   Agent   â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  (LLM +   â”‚               â”‚\n",
    "                â”‚   tools)  â”‚               â”‚\n",
    "                â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜               â”‚\n",
    "                      â”‚                     â”‚\n",
    "               has tool calls?              â”‚\n",
    "                /           \\               â”‚\n",
    "              yes            no             â”‚\n",
    "              /               \\             â”‚\n",
    "    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚\n",
    "    â”‚  Tool Node  â”‚     â”‚   END   â”‚        â”‚\n",
    "    â”‚ (X API +    â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚\n",
    "    â”‚  GitHub MCP)â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "**ðŸ“š Documentation:**\n",
    "- [LangGraph ReAct Agent](https://langchain-ai.github.io/langgraph/tutorials/introduction/)\n",
    "- [MemorySaver (Checkpointing)](https://langchain-ai.github.io/langgraph/concepts/persistence/)\n",
    "- [ToolNode Prebuilt](https://langchain-ai.github.io/langgraph/reference/prebuilt/#langgraph.prebuilt.tool_node.ToolNode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "# Combine all tools: X API tools + GitHub MCP tools\n",
    "all_tools = x_api_tools + github_mcp_tools\n",
    "print(f\"Total tools available to agent: {len(all_tools)}\")\n",
    "print(f\"  X API tools: {[t.name for t in x_api_tools]}\")\n",
    "print(f\"  GitHub MCP tools: {[t.name for t in github_mcp_tools]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define the Agent State\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "# Step 2: Define the system prompt\n",
    "SYSTEM_PROMPT = \"\"\"You are an AI assistant that can search X/Twitter posts and manage GitHub repositories.\n",
    "\n",
    "You have two categories of tools:\n",
    "1. X API tools: search_recent_posts, get_user_posts â€” for searching and retrieving X/Twitter posts\n",
    "2. GitHub MCP tools: for creating repos, committing files, creating branches, opening PRs, etc.\n",
    "\n",
    "When asked to summarize posts, retrieve them first using the X API tools, then provide a structured\n",
    "markdown summary with: Overview, Key Themes, Notable Posts, and Summary Statistics.\n",
    "\n",
    "When asked to perform GitHub operations, use the appropriate GitHub MCP tool.\n",
    "Always use the available tools when appropriate. Be concise in your responses.\"\"\"\n",
    "\n",
    "\n",
    "# Step 3: Bind tools to the LLM\n",
    "llm_with_tools = llm.bind_tools(all_tools)\n",
    "\n",
    "\n",
    "# Step 4: Define the agent node\n",
    "def agent_node(state: AgentState):\n",
    "    \"\"\"The agent node â€” calls the LLM with the current conversation and available tools.\"\"\"\n",
    "    messages = [SystemMessage(content=SYSTEM_PROMPT)] + state[\"messages\"]\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# Step 5: Define the tool node\n",
    "tool_node = ToolNode(all_tools, handle_tool_errors=True)\n",
    "\n",
    "\n",
    "# Step 6: Define routing logic\n",
    "def should_continue(state: AgentState) -> Literal[\"tools\", \"end\"]:\n",
    "    \"\"\"Determine whether to call tools or end the conversation.\"\"\"\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return \"end\"\n",
    "\n",
    "\n",
    "# Step 7: Build the graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"agent\", agent_node)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "workflow.add_edge(START, \"agent\")\n",
    "workflow.add_conditional_edges(\"agent\", should_continue, {\"tools\": \"tools\", \"end\": END})\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "# Compile with MemorySaver for short-term memory across turns\n",
    "checkpointer = MemorySaver()\n",
    "agent = workflow.compile(checkpointer=checkpointer)\n",
    "\n",
    "print(\"Agent compiled with memory and tools!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the graph to confirm our architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(agent.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function for running the agent\n",
    "\n",
    "We'll use a single `thread_id` throughout the notebook so the agent remembers previous interactions (short-term memory via the checkpointer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a consistent thread_id so the agent remembers context across all tasks\n",
    "config = {\"configurable\": {\"thread_id\": \"mcp-workflow-1\"}}\n",
    "\n",
    "\n",
    "async def ask_agent(user_message: str) -> str:\n",
    "    \"\"\"Send a message to the agent and return its final response.\"\"\"\n",
    "    response = await agent.ainvoke(\n",
    "        {\"messages\": [HumanMessage(content=user_message)]},\n",
    "        config,\n",
    "    )\n",
    "    return response[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Test the Agent â€” Search & Summarize X Posts\n",
    "\n",
    "Let's put the agent through its paces. First, we'll ask it to search for posts and generate a summary. Because we're using `MemorySaver` with a consistent `thread_id`, the agent will remember the posts it found when we ask it to summarize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask the agent to fetch posts â€” it will use the get_user_posts tool\n",
    "result = await ask_agent(\"Get recent posts from @llm_wizard on X/Twitter.\")\n",
    "print(result[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask the agent to summarize â€” it remembers the posts from the previous turn!\n",
    "summary = await ask_agent(\n",
    "    \"Now summarize those posts into a structured markdown report with sections for: \"\n",
    "    \"Overview, Key Themes, Notable Posts, and Summary Statistics. \"\n",
    "    \"Format it so it can be saved directly as a summary.md file.\"\n",
    ")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the summary locally for reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"summary.md\", \"w\") as f:\n",
    "    f.write(summary)\n",
    "\n",
    "print(\"Summary saved to summary.md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### â“ Question #1:\n",
    "\n",
    "\n",
    "\n",
    "##### Answer:\n",
    "\n",
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ—ï¸ Activity #1:\n",
    "\n",
    "Your task is to extend the agent with a **new custom X API tool** and verify it works end-to-end.\n",
    "\n",
    "1. **Create a new `@tool` function** called `get_user_profile` that retrieves a user's public profile information using the X API v2 [`GET /2/users/by/username/:username`](https://developer.x.com/en/docs/x-api/users/lookup/api-reference/get-users-by-username-username) endpoint. It should return:\n",
    "   - Display name\n",
    "   - Bio / description\n",
    "   - Follower count\n",
    "   - Following count\n",
    "   - Post count\n",
    "   - Account creation date\n",
    "\n",
    "2. **Rebuild the agent** with the updated tool set â€” add your new tool to `x_api_tools`, re-combine with the MCP tools, re-bind tools to the LLM, and recompile the graph\n",
    "\n",
    "3. **Test it** by asking the agent to:\n",
    "   - Retrieve the profile of an AI thought leader of your choice\n",
    "   - Compare that profile with the posts you already retrieved in Task 5 â€” does the bio match the posting themes?\n",
    "\n",
    "> HINT: The X API v2 user lookup endpoint uses the same Bearer Token authentication. You'll need `user.fields=description,public_metrics,created_at` in your request params."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Phase 2: MCP Workflow Through the Agent\n",
    "\n",
    "Now we'll use the same agent to perform all GitHub repository operations through the **GitHub MCP tools**. Because the agent has memory, it already knows the summary it generated in Phase 1.\n",
    "\n",
    "Each task below sends a natural language instruction to the agent. The agent decides which GitHub MCP tool(s) to call to fulfill the request."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: Create a New Repository\n",
    "\n",
    "The agent will use the `create_repository` MCP tool to create a new repo on your GitHub account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await ask_agent(\n",
    "    \"Using your GitHub tools, create a new public repository on my account called \"\n",
    "    \"`x-post-summarizer-2026`. Add a description: 'AI-generated summary of a public \"\n",
    "    \"figure's 2026 X posts, built with LangGraph, MCP tools, and the X API.' \"\n",
    "    \"Initialize it with a README.\"\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7: Commit the Summary to Your Repo\n",
    "\n",
    "The agent remembers the summary it generated earlier (short-term memory) and can commit it directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await ask_agent(\n",
    "    \"Using your GitHub tools, create a new file called `summary.md` in the \"\n",
    "    \"`x-post-summarizer-2026` repo on the `main` branch. The file should contain \"\n",
    "    \"the X post summary you generated earlier. Use the commit message: \"\n",
    "    \"'Add 2026 X post summary'.\"\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8: Create a Feature Branch and Add Metadata\n",
    "\n",
    "The agent will use `create_branch` and `create_or_update_file` MCP tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await ask_agent(\n",
    "    \"Create a new branch called `add-metadata` in my `x-post-summarizer-2026` repo. \"\n",
    "    \"On that branch, create a file called `metadata.json` that contains: the account \"\n",
    "    \"handle analyzed, the date range of posts, the number of posts analyzed, and the \"\n",
    "    \"top 5 themes identified from the summary. Commit it with the message \"\n",
    "    \"'Add analysis metadata'.\"\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 9: Open a Pull Request\n",
    "\n",
    "The agent will use the `create_pull_request` MCP tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await ask_agent(\n",
    "    \"Open a pull request in my `x-post-summarizer-2026` repo from the `add-metadata` \"\n",
    "    \"branch to `main`. Title it 'Add analysis metadata' and include a description \"\n",
    "    \"summarizing what the metadata file contains.\"\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 10: Commit the X API Script\n",
    "\n",
    "We'll ask the agent to commit a clean version of the X search script â€” reading credentials from environment variables, no hardcoded keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_search_script = '''import requests\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "BEARER_TOKEN = os.environ.get(\"X_BEARER_TOKEN\")\n",
    "\n",
    "def search_recent_posts(query: str, max_results: int = 20) -> dict:\n",
    "    \"\"\"Search recent X posts using the v2 API.\"\"\"\n",
    "    url = \"https://api.x.com/2/tweets/search/recent\"\n",
    "    headers = {\"Authorization\": f\"Bearer {BEARER_TOKEN}\"}\n",
    "    params = {\n",
    "        \"query\": query,\n",
    "        \"max_results\": min(max_results, 100),\n",
    "        \"tweet.fields\": \"created_at,public_metrics,author_id,text\",\n",
    "        \"expansions\": \"author_id\",\n",
    "        \"user.fields\": \"name,username\",\n",
    "    }\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "def get_user_posts(username: str, max_results: int = 20) -> dict:\n",
    "    \"\"\"Get recent posts from a specific user.\"\"\"\n",
    "    query = f\"from:{username} -is:retweet\"\n",
    "    return search_recent_posts(query, max_results)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import sys\n",
    "    handle = sys.argv[1] if len(sys.argv) > 1 else \"llM_wizard\"\n",
    "    print(f\"Searching for recent posts from @{handle}...\")\n",
    "    results = get_user_posts(handle)\n",
    "    with open(\"posts.json\", \"w\") as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    tweets = results.get(\"data\", [])\n",
    "    print(f\"Found {len(tweets)} posts.\")\n",
    "    for tweet in tweets:\n",
    "        print(f\"  [{tweet[\\\"created_at\\\"][:10]}] {tweet[\\\"text\\\"][:100]}...\")\n",
    "'''\n",
    "\n",
    "result = await ask_agent(\n",
    "    f\"Using your GitHub tools, create a new file called `x_search.py` in the \"\n",
    "    f\"`x-post-summarizer-2026` repo on the `main` branch. Use the commit message: \"\n",
    "    f\"'Add X API search script'. Here is the file content:\\n\\n{x_search_script}\"\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 11: Update the README\n",
    "\n",
    "The agent already knows everything about the project from its conversation memory â€” what account was analyzed, how the project was built, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await ask_agent(\n",
    "    \"Update the README.md in my `x-post-summarizer-2026` repo on main to include: \"\n",
    "    \"a project description explaining this repo summarizes a public figure's 2026 X \"\n",
    "    \"posts using AI, the handle analyzed, how the project was built (using a LangGraph \"\n",
    "    \"agent with GitHub MCP tools for repo operations and the X API v2 for post \"\n",
    "    \"retrieval), and instructions for someone else to replicate the process â€” including \"\n",
    "    \"how to set up their X API Bearer Token and install Python dependencies.\"\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### â“ Question #2:\n",
    "\n",
    "Compare using GitHub MCP tools (through a LangGraph agent) to traditional `git` commands. What felt easier? What felt harder or less transparent?\n",
    "\n",
    "##### Answer:\n",
    "\n",
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### â“ Question #3:\n",
    "\n",
    "You used MCP for GitHub but wrapped the X API as a `@tool` directly. What are the tradeoffs of consuming an API through an MCP server versus wrapping it as a LangChain tool? When would each approach make more sense?\n",
    "\n",
    "##### Answer:\n",
    "\n",
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ—ï¸ Activity #1:\n",
    "\n",
    "Your task is to extend the MCP workflow by building a **Multi-Account Comparison Pipeline** through the agent.\n",
    "\n",
    "You are expected to:\n",
    "\n",
    "1. **Retrieve posts from a second X account** â€” choose another public figure or thought leader in a related field\n",
    "\n",
    "2. **Generate a structured comparison** by asking the agent to create a `comparison.md` file that includes:\n",
    "   - Side-by-side topic analysis for both accounts\n",
    "   - Tone and sentiment differences\n",
    "   - Posting frequency comparison\n",
    "   - Top 3 most notable posts from each account\n",
    "   - A brief conclusion about each account's focus area\n",
    "\n",
    "3. **Commit through the MCP workflow**:\n",
    "   - Create a new branch called `add-comparison` in your `x-post-summarizer-2026` repo\n",
    "   - Commit `comparison.md` to that branch\n",
    "   - Open a pull request to merge it into `main`\n",
    "\n",
    "> NOTE: The agent already has memory of the first account's posts from Phase 1. You only need to fetch posts from the second account â€” the agent will use its memory for the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
