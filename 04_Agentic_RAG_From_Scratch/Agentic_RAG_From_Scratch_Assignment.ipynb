{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Agentic RAG From Scratch: Building with LangGraph and Open-Source Models\n",
    "\n",
    "In this notebook, we'll look under the hood of `create_agent` and build an agentic RAG application **from scratch** using LangGraph's low-level primitives and locally-hosted open-source models.\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Understand LangGraph's core constructs: StateGraph, nodes, edges, and conditional routing\n",
    "- Build a ReAct agent from scratch without high-level abstractions\n",
    "- Use Ollama to run open-source models locally (gpt-oss:20b + embeddinggemma)\n",
    "- Transition from `aimakerspace` utilities to the LangChain ecosystem\n",
    "\n",
    "## Table of Contents:\n",
    "\n",
    "- **Breakout Room #1:** LangGraph Fundamentals & Building Agents from Scratch\n",
    "  - Task 1: Dependencies & Ollama Setup\n",
    "  - Task 2: LangGraph Core Concepts (StateGraph, Nodes, Edges)\n",
    "  - Task 3: Building a ReAct Agent from Scratch\n",
    "  - Task 4: Adding Tools to Your Agent\n",
    "  - Question #1 & Question #2\n",
    "  - Activity #1: Implement a Custom Routing Function\n",
    "\n",
    "- **Breakout Room #2:** Agentic RAG with Local Models\n",
    "  - Task 5: Loading & Chunking with LangChain\n",
    "  - Task 6: Setting up Qdrant with Local Embeddings\n",
    "  - Task 7: Creating a RAG Tool\n",
    "  - Task 8: Building Agentic RAG from Scratch\n",
    "  - Question #3 & Question #4\n",
    "  - Activity #2: Extend the Agent with Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "---\n",
    "# Breakout Room #1\n",
    "## LangGraph Fundamentals & Building Agents from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## Task 1: Dependencies & Ollama Setup\n",
    "\n",
    "Before we begin, make sure you have:\n",
    "\n",
    "1. **Ollama installed** - Download from [ollama.com](https://ollama.com/)\n",
    "2. **Ollama running** - Start with `ollama serve` in a terminal\n",
    "3. **Models pulled** - Run these commands:\n",
    "\n",
    "```bash\n",
    "# Chat model for reasoning and generation (~12GB)\n",
    "ollama pull gpt-oss:20b\n",
    "\n",
    "# my mac is old so did\n",
    "ollama pull llama2:13b\n",
    "\n",
    "# Embedding model for RAG (~622MB)\n",
    "ollama pull embeddinggemma\n",
    "```\n",
    "\n",
    "> **Note**: If you don't have enough RAM/VRAM for `gpt-oss:20b` (requires 16GB+ VRAM or 24GB+ RAM), you can substitute with `llama3.2:3b` or another smaller model.\n",
    "\n",
    "**ðŸ“š Documentation:**\n",
    "- [Ollama Installation Guide](https://ollama.com/download)\n",
    "- [gpt-oss Model Card](https://ollama.com/library/gpt-oss)\n",
    "- [EmbeddingGemma Model Card](https://ollama.com/library/embeddinggemma)\n",
    "- [langchain-ollama Integration](https://python.langchain.com/docs/integrations/providers/ollama/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports we'll use throughout the notebook\n",
    "import os\n",
    "import getpass\n",
    "import json\n",
    "from uuid import uuid4\n",
    "from typing import Annotated, TypedDict, Literal\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()  # Required for async operations in Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "101cd6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith tracing enabled. Project: pr-ample-bean-55\n"
     ]
    }
   ],
   "source": [
    "### SETENV\n",
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "# openai.api_key = getpass(\"OpenAI API Key: \")\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai.api_key\n",
    "langchain_key = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "#os.environ[\"LANGCHAIN_PROJECT\"] = f\"AIE9 - The Agent Loop - {uuid4().hex[0:8]}\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"pr-ample-bean-55\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"pr-ample-bean-55\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = langchain_key\n",
    "\n",
    "\n",
    "if not os.environ[\"LANGCHAIN_API_KEY\"]:\n",
    "    os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"\n",
    "    print(\"LangSmith tracing disabled\")\n",
    "else:\n",
    "    print(f\"LangSmith tracing enabled. Project: {os.environ['LANGCHAIN_PROJECT']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3ba5e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LANGCHAIN_TRACING_V2 = true\n",
      "âœ… LANGCHAIN_API_KEY is set\n",
      "âœ… LANGCHAIN_PROJECT = pr-ample-bean-55\n",
      "\n",
      "âœ… All environment variables look good!\n",
      "âœ… LangSmith connection works!\n",
      "Your projects: ['pr-ample-bean-55', 'AIE9 - The Agent Loop - f45471ab', 'AIE9 - The Agent Loop - f84c617b']\n",
      "Hello in French is \"Bonjour.\"\n",
      "TEST LANGSMITH TRACING!!!LangSmith\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is the weather in San Francisco?', additional_kwargs={}, response_metadata={}, id='65860c3c-7b24-4dd5-9e45-a9d269567cd8'),\n",
       "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 142, 'total_tokens': 166, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-D1gUgqwkzINwEGCK6XpaMayMvbhZp', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019bf224-a31a-7203-95b8-6b0dd53f3098-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'San Francisco'}, 'id': 'call_6b2oKDJ6TPjnsjeMGwMM8GTP', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 142, 'output_tokens': 24, 'total_tokens': 166, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content=\"It's always sunny in San Francisco!\", name='get_weather', id='81b5e632-af1a-4d96-bebd-1a2faa406bb4', tool_call_id='call_6b2oKDJ6TPjnsjeMGwMM8GTP'),\n",
       "  AIMessage(content='According to the weather service: \"It\\'s always sunny in San Francisco!\"\\n\\nWould you like more detail (current temperature, hourly forecast, chance of rain, wind, or a multi-day forecast)?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 175, 'prompt_tokens': 178, 'total_tokens': 353, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 128, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-D1gUiK0JnHmoXjXC0k7IiD898pJFw', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019bf224-ab8b-7351-b992-a932222f20e6-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 178, 'output_tokens': 175, 'total_tokens': 353, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 128}})]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # lets test langsmith configuration\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "issues = []\n",
    "\n",
    "if os.getenv(\"LANGCHAIN_TRACING_V2\") != \"true\":\n",
    "    issues.append(\"âŒ LANGCHAIN_TRACING_V2 is not 'true'\")\n",
    "else:\n",
    "    print(\"âœ… LANGCHAIN_TRACING_V2 = true\")\n",
    "\n",
    "if not os.getenv(\"LANGCHAIN_API_KEY\"):\n",
    "    issues.append(\"âŒ LANGCHAIN_API_KEY is not set\")\n",
    "else:\n",
    "    print(\"âœ… LANGCHAIN_API_KEY is set\")\n",
    "\n",
    "project = os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "if not project:\n",
    "    issues.append(\"âš ï¸ LANGCHAIN_PROJECT not set (will use 'default')\")\n",
    "else:\n",
    "    print(f\"âœ… LANGCHAIN_PROJECT = {project}\")\n",
    "\n",
    "if issues:\n",
    "    print(\"\\nIssues found:\")\n",
    "    for issue in issues:\n",
    "        print(f\"  {issue}\")\n",
    "else:\n",
    "    print(\"\\nâœ… All environment variables look good!\")\n",
    "\n",
    "\n",
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "try:\n",
    "    projects = list(client.list_projects(limit=3))\n",
    "    print(\"âœ… LangSmith connection works!\")\n",
    "    print(\"Your projects:\", [p.name for p in projects])\n",
    "except Exception as e:\n",
    "    print(f\"âŒ LangSmith connection failed: {e}\")\n",
    "\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "response = llm.invoke(\"Say hello in French\")\n",
    "print(response.content)\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "from langsmith import traceable\n",
    "\n",
    "@traceable\n",
    "def format_prompt(subject):\n",
    "    \"TEST LANGSMITH TRACING!!!\"+subject\n",
    "    print(\"TEST LANGSMITH TRACING!!!\"+subject)\n",
    "test_langsmith = format_prompt(\"LangSmith\")\n",
    "\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"openai:gpt-5-mini\",\n",
    "    tools=[get_weather],\n",
    "    system_prompt=\"You are a helpful assistant\",\n",
    ")\n",
    "\n",
    "# Run the agent\n",
    "agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in San Francisco?\"}]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Verify Ollama is running and models are available\n",
    "# from langchain_ollama import ChatOllama, OllamaEmbeddings\n",
    "# usedModel = \"llama2:13b\" # \"llama2:13b\", \"gpt-oss:20b\"\n",
    "# # had to\n",
    "# # ollama pull llama2:13b\n",
    "# # ollama pull embeddinggemma\n",
    "# # one window ollama run llama2:13b\n",
    "# # one window ollama run embeddinggemma -> didnt work.. \n",
    "# # Test connection to Ollama\n",
    "# try:\n",
    "#     test_llm = ChatOllama(model=usedModel, temperature=0)\n",
    "#     test_response = test_llm.invoke(\"Say 'Ollama is working!' in exactly 3 words.\")\n",
    "#     print(f\"Chat Model Test: {test_response.content}\")\n",
    "    \n",
    "#     test_embeddings = OllamaEmbeddings(model=\"embeddinggemma\")\n",
    "#     test_vector = test_embeddings.embed_query(\"test\")\n",
    "#     print(f\"Embedding Model Test: Vector dimension = {len(test_vector)}\")\n",
    "#     print(\"\\nOllama is ready!\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Error connecting to Ollama: {e}\")\n",
    "#     print(\"\\nMake sure:\")\n",
    "#     print(\"1. Ollama is installed: https://ollama.com/\")\n",
    "#     print(\"2. Ollama is running: 'ollama serve'\")\n",
    "#     print(\"3. Models are pulled: 'ollama pull gpt-oss:20b' and 'ollama pull embeddinggemma'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## Task 2: LangGraph Core Concepts\n",
    "\n",
    "In Session 3, we used `create_agent` which abstracts away the complexity. Now let's understand what's happening under the hood!\n",
    "\n",
    "### LangGraph models workflows as **graphs** with three key components:\n",
    "\n",
    "### 1. State\n",
    "A shared data structure that represents the current snapshot of your application:\n",
    "\n",
    "```python\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]  # Conversation history\n",
    "```\n",
    "\n",
    "The `add_messages` **reducer** ensures new messages are appended (not replaced) when the state updates.\n",
    "\n",
    "### 2. Nodes\n",
    "Python functions that encode the logic of your agent:\n",
    "- Receive the current state\n",
    "- Perform computation or side-effects\n",
    "- Return an updated state\n",
    "\n",
    "### 3. Edges\n",
    "Functions that determine which node to execute next:\n",
    "- **Normal edges**: Always go to a specific node\n",
    "- **Conditional edges**: Choose the next node based on state\n",
    "\n",
    "**ðŸ“š Documentation:**\n",
    "- [LangGraph Low-Level Concepts](https://langchain-ai.github.io/langgraph/concepts/low_level/)\n",
    "- [LangGraph Quickstart](https://langchain-ai.github.io/langgraph/tutorials/introduction/)\n",
    "- [StateGraph API Reference](https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.StateGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple echo graph created!\n"
     ]
    }
   ],
   "source": [
    "# Let's build our first LangGraph workflow - a simple echo graph\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# Step 1: Define the State\n",
    "class SimpleState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# Step 2: Define Nodes (functions that process state)\n",
    "def echo_node(state: SimpleState):\n",
    "    \"\"\"A simple node that echoes the last message.\"\"\"\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    echo_response = AIMessage(content=f\"You said: {last_message.content}\")\n",
    "    return {\"messages\": [echo_response]}\n",
    "\n",
    "# Step 3: Build the Graph\n",
    "echo_graph = StateGraph(SimpleState)\n",
    "\n",
    "# Add nodes\n",
    "echo_graph.add_node(\"echo\", echo_node)\n",
    "\n",
    "# Add edges (START -> echo -> END)\n",
    "echo_graph.add_edge(START, \"echo\")\n",
    "echo_graph.add_edge(\"echo\", END)\n",
    "\n",
    "# Compile the graph\n",
    "echo_app = echo_graph.compile()\n",
    "\n",
    "print(\"Simple echo graph created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the graph structure\n",
    "try:\n",
    "    from IPython.display import display, Image\n",
    "    display(Image(echo_app.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Could not display graph image: {e}\")\n",
    "    print(\"\\nGraph structure (ASCII):\")\n",
    "    print(echo_app.get_graph().draw_ascii())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation:\n",
      "  [Human]: Hello, LangGraph!\n",
      "  [AI]: You said: Hello, LangGraph!\n"
     ]
    }
   ],
   "source": [
    "# Test the echo graph\n",
    "result = echo_app.invoke({\"messages\": [HumanMessage(content=\"Hello, LangGraph!\")]})\n",
    "\n",
    "print(\"Conversation:\")\n",
    "for msg in result[\"messages\"]:\n",
    "    role = \"Human\" if isinstance(msg, HumanMessage) else \"AI\"\n",
    "    print(f\"  [{role}]: {msg.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## Task 3: Building a ReAct Agent from Scratch\n",
    "\n",
    "Now let's build something more sophisticated: a **ReAct agent** that can:\n",
    "1. **Reason** about what to do\n",
    "2. **Act** by calling tools\n",
    "3. **Observe** results\n",
    "4. **Repeat** until done\n",
    "\n",
    "This is exactly what `create_agent` does under the hood. Let's build it ourselves!\n",
    "\n",
    "### The Agent Loop Architecture\n",
    "\n",
    "```\n",
    "                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                    â”‚    START     â”‚\n",
    "                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                           â”‚\n",
    "                           â–¼\n",
    "                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "             â”Œâ”€â”€â”€â”€â”€â–ºâ”‚    agent     â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "             â”‚      â”‚  (call LLM)  â”‚         â”‚\n",
    "             â”‚      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚\n",
    "             â”‚             â”‚                 â”‚\n",
    "             â”‚             â–¼                 â”‚\n",
    "             â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚\n",
    "             â”‚      â”‚ should_      â”‚         â”‚\n",
    "             â”‚      â”‚ continue?    â”‚         â”‚\n",
    "             â”‚      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚\n",
    "             â”‚             â”‚                 â”‚\n",
    "             â”‚    tool_calls?                â”‚\n",
    "             â”‚     â”‚           â”‚             â”‚\n",
    "             â”‚    YES         NO             â”‚\n",
    "             â”‚     â”‚           â”‚             â”‚\n",
    "             â”‚     â–¼           â–¼             â”‚\n",
    "             â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”         â”‚\n",
    "             â”‚ â”‚ tools  â”‚  â”‚  END  â”‚         â”‚\n",
    "             â””â”€â”¤(executeâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚\n",
    "               â”‚ tools) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "               â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "**ðŸ“š Documentation:**\n",
    "- [How to create a ReAct agent from scratch](https://langchain-ai.github.io/langgraph/how-tos/react-agent-from-scratch/)\n",
    "- [ReAct Agent Conceptual Guide](https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/#react-agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AgentState defined with messages field\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import BaseMessage, SystemMessage, ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "# Step 1: Define the Agent State\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"The state of our agent - just a list of messages.\"\"\"\n",
    "    messages: Annotated[list[BaseMessage], add_messages]\n",
    "\n",
    "print(\"AgentState defined with messages field\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Initialize our local LLM with Ollama\n",
    "# Per above, defaulting back to openai for now since I cant get a model that supports tool calls locally.\n",
    "\n",
    "# llm = ChatOllama(\n",
    "#     model=usedModel,\n",
    "#     temperature=0,  # Deterministic for reproducibility\n",
    "# )\n",
    "\n",
    "# print(f\"LLM initialized: {llm.model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## Task 4: Adding Tools to Your Agent\n",
    "\n",
    "Tools are functions that the agent can call. We use the `@tool` decorator and **bind** them to the LLM.\n",
    "\n",
    "**ðŸ“š Documentation:**\n",
    "- [LangChain Tools Conceptual Guide](https://python.langchain.com/docs/concepts/tools/)\n",
    "- [@tool Decorator Reference](https://python.langchain.com/api_reference/core/tools/langchain_core.tools.convert.tool.html)\n",
    "- [ToolNode Prebuilt](https://langchain-ai.github.io/langgraph/reference/prebuilt/#langgraph.prebuilt.tool_node.ToolNode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tools defined and bound to LLM:\n",
      "  - calculate: Evaluate a mathematical expression. Use this for a...\n",
      "  - get_current_time: Get the current date and time. Use this when the u...\n",
      "  - return_sqrt: Your tool should return the square root of any num...\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Define Tools\n",
    "@tool\n",
    "def calculate(expression: str) -> str:\n",
    "    \"\"\"Evaluate a mathematical expression. Use this for any math calculations.\n",
    "    \n",
    "    Args:\n",
    "        expression: A mathematical expression to evaluate (e.g., '2 + 2', '10 * 5')\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Using eval with restricted globals for safety\n",
    "        result = eval(expression, {\"__builtins__\": {}}, {})\n",
    "        return f\"The result of {expression} is {result}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error evaluating expression: {e}\"\n",
    "\n",
    "@tool\n",
    "def get_current_time() -> str:\n",
    "    \"\"\"Get the current date and time. Use this when the user asks about the current time or date.\"\"\"\n",
    "    from datetime import datetime\n",
    "    return f\"The current date and time is: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
    "\n",
    "\n",
    "import math\n",
    "# HW create custom square root tool\n",
    "@tool\n",
    "def return_sqrt(num: int):\n",
    "    \"\"\"\n",
    "    Your tool should return the square root of any number you are given\n",
    "    \n",
    "    Args:\n",
    "    num: The number to find the square root of\n",
    "    \"\"\"\n",
    "    return str(math.sqrt(num))\n",
    "\n",
    "# Create our tool list\n",
    "tools = [calculate, get_current_time, return_sqrt]\n",
    "# Bind tools to the LLM - this tells the LLM about available tools\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "print(\"Tools defined and bound to LLM:\")\n",
    "for t in tools:\n",
    "    print(f\"  - {t.name}: {t.description[:50]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cell-17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent node defined\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Define the Agent Node (calls the LLM)\n",
    "SYSTEM_PROMPT = \"\"\"You are a helpful assistant that can perform calculations and tell the time.\n",
    "Always use the available tools when appropriate.\n",
    "Be concise in your responses.\"\"\"\n",
    "\n",
    "def agent_node(state: AgentState):\n",
    "    \"\"\"The agent node - calls the LLM with the current conversation.\"\"\"\n",
    "    # Prepare messages with system prompt\n",
    "    messages = [SystemMessage(content=SYSTEM_PROMPT)] + state[\"messages\"]\n",
    "    \n",
    "    # Call the LLM\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    \n",
    "    # Return the response to be added to state\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "print(\"Agent node defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cell-18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool node created using ToolNode prebuilt\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Define the Tool Node (executes tools)\n",
    "# We can use LangGraph's prebuilt ToolNode for convenience\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "print(\"Tool node created using ToolNode prebuilt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cell-19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditional routing function defined\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Define the Conditional Edge (routing logic)\n",
    "def should_continue(state: AgentState) -> Literal[\"tools\", \"end\"]:\n",
    "    \"\"\"Determine whether to call tools or end the conversation.\"\"\"\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    \n",
    "    # If the LLM made tool calls, route to tools node\n",
    "    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    \n",
    "    # Otherwise, end the conversation\n",
    "    return \"end\"\n",
    "\n",
    "print(\"Conditional routing function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cell-20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReAct agent built from scratch!\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Build the Graph!\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"agent\", agent_node)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Set the entry point\n",
    "workflow.add_edge(START, \"agent\")\n",
    "\n",
    "# Add conditional edge from agent\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"tools\": \"tools\",  # If should_continue returns \"tools\", go to tools node\n",
    "        \"end\": END         # If should_continue returns \"end\", finish\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add edge from tools back to agent (the loop!)\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "# Compile the graph\n",
    "agent = workflow.compile()\n",
    "\n",
    "print(\"ReAct agent built from scratch!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cell-21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANgAAAERCAIAAACW0v5yAAAQAElEQVR4nOydB3xTVfvHn3tvRvfeLW0pZbVlCsgLgmyVWZa+TBV52fxBBUSRoYIIojhAFAUZgqCCLEFUppRZkC2ztLSldK+Upk2T+39ubglpSRdtkpPkfD98ys29Jzdp88s5zzjnORKe54FCMTcSoFAIgAqRQgRUiBQioEKkEAEVIoUIqBApRECFWAOSbiqvxeZlpxYXKzWaEl6jLt+AYYHXGDiJPH4eOABDd9DwPMMz5W+LUTb9k3jI8KBhyj+fLX9SImdkdqyjszQw3L7Fsy5AKgyNI1bJv6cUZw9m5WWXaNQajmOkdqydHccwoC4pLy5GwvAl5f+eghAZ4B/THMexavVjd+AY0EC5D4VhUXSoMP1TQsvHXwvwtcreEt+tugRUxXzRA7W6hJc7sMGNHXuN9AHCoEKsjBux+Ud2ZKiKeK8AWatnPRq2dgBLprAQ/t6Wevf6A+zR64U79BvvD8RAhVghmxYn5mYUN2rl3IO8/qOWJPxbeHBrmqpIPXhqsGcAEeYZFaJhVs287eIuHfFOMFgvp/fnnv0rI7KDW+eBnmBuqBANsGrW7eadPDr2cwcb4OvZcX3GBNRrZAdmhQqxPKtmxnWK9onq6AQ2w7dv3wlr7tx9mBeYDxYoeqx+O65VVw+bUiHyv8X1b57PvX5GAeaDCvERm5cmOrlJ2vd2A9vjhVcCDvyUCuaDCrGUhKvKnNSi4W9Zs3dSCSFN7T395T8uSQQzQYVYyoEf74dEOIMN89IbQZmpRfkZGjAHVIgCiTeLlQ/UfV7zBdvGy1++Z20ymAMqRIFjv6Y5e8nAtMyePXvnzp1QQ27fvt23b18wDh36e2elFYE5oEIUyM0sjmxv6gkBV69ehZrzZM+qJsGN7RiGOftXLpgcGkcERZZm/aI7kz9pAMYhJiZmw4YNV65c8fLyatGixdSpU/GgTZs24lUnJ6fDhw9jP/fLL7+cOXPm3r17YWFh0dHRQ4YMERt079597NixBw8e/Oeff0aNGrVx40bx/Ouvvz5ixAioazZ+mGDvwA2ZHgSmhU4Dg6un8zgJA8bh2rVr06ZNmzBhwnvvvRcXF/fll18uWLBgxYoVqM6OHTvOnTt3wIAB2OyTTz5BCc6ZMwc7pPj4+CVLlvj7+2MDvCSVSn/99dd27dqhHJ966ils8Mcff+zZsweMg4evPC1JCSaHChEy7imldsYyUc6fP29nZzdmzBiWZf38/CIiIm7duvV4s8WLFxcUFAQEBOAxdpa7du06fvy4KERUnqur64wZM8AkuPvIkm49AJNDhQhFDzQSqbF6xJYtWyqVyunTpz/99NOdO3euV6+eblDWBw2kLVu2YDeZkJAgngkMDNRdRfmCqXBw4dQaM1hr1FkBtTD52Vh/+iZNmnzxxRfe3t44KA8cOHDSpEkXLlwo10aj0eDwjQbilClTDh06FBsbi6akfgOZzHQePcsIk27B5FAhgoODRGPMIG6HDh3QFty9ezdah7m5udg7lpSU6DdAOxJdGXQ+unbt6uwsBNXz8/PBTBQq1IwZdEiFCODqLSkqNJYSz549i9YeHmCniPG/N998E0WWkpKi3yYnJwd/+viUTr+N0wJmIvO+SsqZQRVUiNCwlYtaZSwh4kA8a9as7du3Z2dnX758GQ1BVCR6xHK5HJV38uRJHIiDg4MlEgnGZfLy8tBl/vjjj9u3b19OrDqwcUZGBkZ8dNZk3ZJ5v8jBlQOTQ4UIPvWk6JtePZEHRmDkyJFoGi5btqxnz57jxo1zdHRcvXo1yg4voSuNdiH2kegUL1y48NKlS926dcMBevLkyRhERNXqQon6PPPMM+gAoRO9f/9+MAL5WcVBjcywNIcGtAW+XxAvs2NHzLbRqTc6clJLNn50Z+ryhmByaI8o8PRzXnnZKrB59m24Z+9khnEZaBxRJOI/Toe3pR7cmt7tJW+DDdDbFVMgj4M5OoXC8NxmTNatXbsWjMM6LVDDt4RB8kWLFkEFZNwr6jMmAMwBHZpLOXsg9+Te9MmfhBu8iqG++/fvG7yE8WrMnRi8hLagzheuc/K1QA3fEjpJnp6G1+zt+DolN6345XkhYA6oEB+xZt4dd2/poKmmzveTAK+Br2bequh7aAKojfiI196vfz+hKOGqGVL+Zmf1nDuR7c25WIcKsQyj3grbu848U5TNyMYPEj18ZF2GmnM5KR2ay6NUaNYsuDN8VrC7jxRsgG+xL/yPS4e+Zi72QIVoAEWOZt37ceHNnZ9/xZpXseSmq7cuT/Dwlw+ZGgjmhgqxQla/E8cwzLODvRu1tsL19j9/lpyWVNi6i+d/+hJRWYUKsTIObE6/fi5XJudCmzn1+K83WD7/nsz/52hOTlqxi6d05NsEZZKoEKvmz42p8dcKipUalmMcXaQOzpy9I8dIGXXxo+KbnIQtrdvJYCxEe4Zj1Oqyf1sGOLb8SZYVKnmqy8wLw5NCzVhebeCj4fB1VbzuuboJbJxEuIn+GREJx5aUwIN81YM8tfKBGljG3Uf2wqgAVx+y/FQqxGqjhMN70tMSihR5Jag5XlNGUizHa9Rl6w0Lf9ryM/sYluc15ZppyxVrJY1hc1Z4zGirHZdvKcJxvPrhC2Fb3afHcsJN9M/o2ktknJ096+ojb9rWOawZobVGqRAJYvjw4QsWLGjUqBHYHjTXTBAlJSXiDDEbhAqRIKgQKURAhUghApVKJZXaRDrncagQCYL2iBQioEKkEAEVIoUIqI1IIQK1Wk17RIqZQRVynHlW0JEAFSIp2LKBCFSI5ECFSCEC9FSoECnmh/aIFCKgQqQQARUihQhsOZoNVIjkQHtEChFQIVKIgAqRQgRUiBQioM4KhQhoj0ghAoZh3N2JKENjFqgQSYFl2YyMDLBVqBBJAcflcluj2RRUiKSAQlSr1WCrUCGSAu0RKURAhUghAipEChFQIVKIgAqRQgRUiBQioEKkEAEVIoUIqBApRECFSCECKkQKEXAcZ8u5ZrpNLkGgFm22U6RCJAhbHp3pzlPmp2XLlizLMoywsZlGoxEPRo8ePX36dLAZaI9ofpo0aSIKEcHRGY/r1as3bNgwsCWoEM3P4MGDZTKZ/plOnTr5+lrznuWPQ4VofoYOHRoaGqp7iBLEM2BjUCESwfDhwx0cSjewbdu2bUhICNgYVIhE0LdvX7FTxO4QRQm2B/Waa0BBLpzZn1FYgDGWMtvEsxJGo+ah7B8SfQ4Nr9E/yYjfer7M3t4MK/jIDPCpaenXrl3z9PSMaBohPJ0TPhpeU/494GsB3vex83hzBhiNxvCnKbeXBIY7RrZ3BFKhQqwumz66m5epksk5FKFGVUYIDKfdbb7sH1LYrJ4ve1K3Ib2+EBleuIANNYLABM9Z247hhDPw2IeD5wUpPyZE/CRR03wFqRm5HatS8ZwEBkwI9A6SAXlQIVaLH5cmaUqY/pMDwZK58nfe+aMZQ18P8vQnTotUiFWzeUkSy7F9/hcAlo8iB3asjJu4NAwIgzorVVCYBbkZRdahQsTJDZzdZNtWpABhUCFWwZnDmRK5Ve1M5h1kl5NeBIRBp4FVQWG+WlNiZdYLX6LUAGFQIVaBmteo1cR9bLWBF34j4r5aVIg2B5neKRWizSGEvhkgDSpEm0NI95DXKVIh2hwEdodAhVglmKljrCvGRWYIgAqxKnjG2nJP1FmxRAQVWpcQS2dVEAYVos3B8yR+s6gQbQ6hR2RpQJtiboQeUUPc4EyFWAUsK/yzJoQekQa0LQ7e6rxmnicxoE2ngVWBsHCEYCG+9/7svft2guVDhWjZXL9+FawCOjTXPQqF4udffjh95kR8/G1PD68OHZ4d8+pEOzs7vJSdnbX4o3lXrl4Mrhc6YMDQpKS7fx87tP77X0C7Te6atV+dPHUsLe1+VFTLgQNebN/+GfGG0YN6vPrKhNzcnPUbVtvb27dt858pk2d4enp17d4Gr3687INVXy/fvfMwWDK0R6wSvqam/fZft2z+cd1LL476cNFn48dPO3zkTxSQeGnpsvfvJsZ/vPSrhR98eupUDP5jH7pCX3y59JdtmwdGv7R50+5nO3ef/96sI0cPiJekUunWrRuw5Y5fD6z/ftuly+fXrf8Gz/++NwZ/zpwxt0YqpM6KZaJd71kjXhw6EpUUElJffHj58oXTZ46PH/d/2KWdPHls6pSZEU2j8Pybb7w7bHhfL28fPC4qKtr/x57hw17p328wPuz9wgB81oaN3+J9xJsEBtYbOWKMcOTkjD3ijRv/wpNCprNChVgVNU/xYQd2JvbER0vm37p9Q6x36O7ugT9vx93En1FRLcRmTk5OrVu3ww4Sj1FYxcXFqDDdTVq2eGrf77ty83JdXVzxYaNGTXWXnJ1dCgoU8KQwRAakqBDrntXffrl37w4clFFYvr5+361ZKTq2+fl5+NPR0UnX0kUrMhDMynz8OXXaa+VulZ2VKQqRqbvRFLtDDXldIhViHYPBnt17tg0ZPLxvn4HiGVFkiFwu+Cuq4mJd4+ycLPHA08sbhMF6Dg7B+nfz8fGDun+Lgt0LhEGFWAWCiViTgQzH4sLCQi8vH/EhDrjHTxwVj+vVE2p83Ym/HRoqrG9H5/rcudO+vv54HBQYLJfL8aBVyzZiY/SvUdO6EmF1CJnOCvWaq4SpkY2IBmJwcCiad8n3ktA7QTe5WVRLHJQLCgoCA4LQg0EPGi+hCj/7fLG/f2kNExTcKy+PR+/k0qXzqF30l2fMmvTZ5x9V/lqoXW9vn9jYk/+cj61+2J1mViySJ5iPOHfOh3Zyu1deHTJydPRTrduNHTsFHw4c3CPl/r1ZM+ZhFGbU6IGvvzEO/Y+oyBZSiVR81n9fGj1zxrzNW9b1G9Dl8y+WBPgHvfnmu1W+1ojhY879c2buvDc1Gste80pr31TB3nX3468UjHq3AdQF2EcqlUr0YMSHb8+ZLuEkH7y/DExIzM7UO5cUEz+um9+orqA9oknB1DD2hZhNQUVu/GHN2bOn+vcfAqaFruKzSOp28dT8+Us+Xvb+t9+tSE9PDQmuP3/uR23btAcKFWKV8BqGrzvrC4OCC9//BMwKXWBPIQJacoRCBjTXbIkImVmOyNoITwqt9GCRCDXWySviVhvo0EyhVAgVIoUIqBCrgJWARGptNiIN31gemhIoUVmbjUi9ZgrFMFSIFCKgQqwCqYyRyq3KRpRKJTJ74naOobNvqsDX30Gjtioh5uUUy+2I+9ypEKugeVdntO3jLz0AayHznrJRK2cgDCrEqmnbw+f47vtgFfz6ZaKdPft0b3cgDDpDu1pkp6h+Wp7oEWgf3NhJbs+WqPX2RWbKrCXgtV9u8QTPAKstzyo2edSQh8erB4v7NvPl71emPfPw0eMvzosBwtKXE/9/dJUFJiO5KOmmwsNfHj3RH8iDCrG63LqWuXdNklziolaV2UJMDA7r/or4UP9YvMQYWvfCPFSP2ECEr+i2eurltVUbrpy9FgAAEABJREFUxXCgdo9x/QO+dA00/+jmCPpbMjkX0tip+3AvIBIqxOoyduzYRYsW+fr6gtEYOXLk3LlzGzduDE/ExYsXp02b5uTk1KlTp+jo6EaNGoHlQG3Eqvnzzz/x53fffWdUFSJ4f3t7e3hSmjVr5unpmZKSsmXLltdff3369OkHDhwAC4H2iJWh0Wj69ev36aefPnEvZWJmzpyJ4hMrjOGbd3Nz8/Pze/7550ePHg1kQ3vECklOTi4sLFy7dq3JVIivKBZtemLatGnDcaXBapRjXl7etWvX1q1bB8RDhWiYt956S6FQODo6Gns41mfy5MmpqalQC6Kiory8yrgj3t7eBw8eBOKhQiwP9klnzpzp1auX6YfjgIAAqVQKtSAyMhK/PLqHLi4u+/fvB0uACrEMGzduxOGsdevW3bt3B5Pz1Vdf+fj4QO0ICwvTaAkNDW3btq2l+Ct00sMj9u3bl5WV5eHhAWYiKSnJ399fZ+Q9Ge3bt8exODY2VnyIIaHAwMAmTZoA2VCvWeDff/9t2rRpYmJivXr1wHz07Nnzp59+cnev4/xb165dd+3a5exMXH5ZHzo0A1pRa9asAaF+oTlVCEKh7ECZTAZ1zc6dOwcMGABkY9M9IhpSGOPYu3dv7969warBLv/DDz9ECxhIxXZ7RLSi5syZgwfkqDAhIcFI/QIaHi+//PLs2bOBVGxXiGiNLV68GEjipZdeUuvP66lTevTogXL88ssvgUhsTogFBQW//fYbHixduhQIA41UicSIcQzsFPPz87dv3w7kYVs2IqbsMPG6bdu2cukHmwLzN6jIdu3aAUnYkBAxOuPg4ODp6QmkgjZiSEgIGB90ojF4jk46EINNDM1FRUVDhw6Vy+Ukq1ClUv33v/8Fk4ABnejoaCAJ6xcixmhiYmLQIqx99syo4Pts0MB0BdZ37NhBlBatfGheuHAhxiyM6gFYLqdPn16/fv3KlSuBAKy5R1y9enVUVJSlqBB7xLt374IJQX+le/fuGOgGArBOIR46dAi0YTnSLKFKyMnJGTt2LJiWQYMGYQ4a+0UwN1YoRPQHb9++jQeurq5gOTAMExoaCiZn6tSpmAD866+/wKxYlY2Ynp7u7e196tSpp59+Gig1YdSoUe+88w6mXsBMWI8Qt2zZkpubO378eLBMMLmXkpISFBQEZqJbt27oSru4uIA5MIUQMatmgi0L0QdE65vwWXeVkJycjDkPlAKYCcz+9e/fXzSvTY8pPEqMJxtPiBgHxr7Ezs6uRYsW+EKOjo7iYkqLA23E4OBgMB/4HV61atXIkSN/+OEHMDmm6BGzsrKMJES8bV5enpubm+6Mh4eHhQqREA4cOPDHH38sWbIETIsFf2bijCl9FVo0xcXF9+7dA3ODkcXIyEjTzxazSCFiR4gOMqsFrIW4uLhZs2YBAYwePVqhUJh4tphFfpBoF2Lo64UXXsAgMFgLmAEy+6IZHW+//TaO0RgIA1NhSUJEcxYDNHggl8vB6ggPDydqxjjmoPH9JCUlgUmwJCGKNUDASkGX//59surSYixp4MCBYBLMI8SrV6/OmTNnyJAhr7322urVqx88KK1QvWvXrmHDhiUmJmJc+vnnn584cSJ6cKCdWY0/t27digmAMWPGbNiwoZbFigjkypUr8+bNA8JALZpmKaoZhIiRW8wmKZXK5cuX45/+zp07M2fOFIUllUqx28Nk8fTp0/ft29epUydsg4ljdEr2aJk0adLnn3/u5+e3adMmsC5kMhlRU6ZF8C1hl4F/djAyZhAixu7RMEcJom0eEhKCmkOpHT9+XLyKjsiIESMw6YkB3i5duqBdiAMWGoU7d+7spAXjrr169WrZsiVYF1FRUfPnzwfywHxVz549Fy1aBMbEDELEcblx48a6qTG+vr7+/v6XL1/WNRDLcGHX6ODggAc4cKMcMcamn3ho2LAhWBdoftSyJp3xQEsRPy+j1lk0w6RRVNiNGzfQBNQ/mZ2drTvGvhCVx3GcLkyIWsTwtX5ZX8zpgXWBJsrmzZsXLlwIRDJlypS5c+deunSpWbNmYATMIETMwmHsvlwx3XKTPlCLKDudE4NdI+oS/UpdA9F9sSYiIiL69esXExPTsWNHIJKDBw++++67YBzMIMT69etjsBS/WLoOLyEhoZydjq6MftYEdenj44NBbN2Z06dPg9VB8jRKNBvc3d2NF8E1g404aNAgzNF9/fXXqDaMl65Zs2bChAnx8fH6bdCJLld8o3PnzseOHTt69Choq4Vcu3YNrJGCggIMWgF53L1716iJHzMIEd1eVCEaeVOnTh07duzFixfRcca8gn4bvFquQBvGF9GsXLVqFf7E1NO4ceMAwPqWIGLEHoMGK1asAMJAIRp1lpplTwN7HDoNzEhgQBfjG8OHDwfjQOhnVqQFbBhMOKHpAsRghUNzdXjcRrQ1OnTogKYzEIONDs2oQnxjT7A23pqGZoxeiWEsIIC2bdueOXMGjAahnxlGDWmdEIye3rx5E/1oMDeJiYnGXl5IbUSiQbOMhGIVxh6XgVgh4tBsfRO9ngCMIa9fv14/EW8WTFC40RTDn5ubW01tRMxHoxCfYGGU9cVuAgIC/Pz80GJmGAbMBA7NYWFhYExMIcQnWOVkliowxIJ/vWeeeQbzouZaI4FDc9euXcGYENp/YO5/9+7dQHnIpk2btm7dCmYCh2YbtRExB22t2eQnA000c23+rVKpMjMz0TwAY0KoEDt27Ni/f3+glGX+/PmmX4SP47IJSswTKkSMWpl+u2TymTx5sukXWBk7uSdCqBAxiL9t2zaglMXHx+e7774D02KCICIQK8SUlJQrV64AxRD79+9H7wFMhU0PzZjZHDJkCFAM8dxzzxl1175y2PTQ7O/vHxERAZQKOHLkiMnq/tj00HzhwoXNmzcDpQIwsq1UKtPT08HIFBQUYNLfBDt2ESpE/BNfvHgRKBUTGBg4fvx4Y2/NYppxGcyyiq86NG/e3NfXFyiVsnHjxhMnThh13DTNuAzECtFHC1AqxdHRsUePHmBMTLZhKqFDM8ZuNmzYAJRqMG3aNONV1ExMTDTN0EyoELOzs8+dOweUarB8+fI9e/aAcTDZ0Ezohj+YZcfvovWV/LI4unTpgip3cnICI0Noj4jxAqrCGrF169aYmBjdw969e0OtwXFJKpWaQIVArBBv3br17bffAqXaYK7lm2++SUtL69Onz1NPPcWy7J07d6B2mCa5J0KoEHNzc2NjY4FSE9C9Gzx4cGpqKsMwhYWFycnJUDtMMB9WB6Hhm/DwcLG6DaX6tGrViuM48Ri/ybXfEMBkLjMQ2yO6urri+AKU6tG5c2d9FYJ2TyRx0+raQIdm4bu4cuVKoFSPo0eP1q9fHx0L3RkcnWtfCNmUQzOhQlQoFCdPngRKtdm+ffukSZMCAgLEChkYlUtJSYHaYcqhmVAbEX//qVOnAqVSrp8pUJVoZyUyKD1oFT4gakbv4zHHL1+6nJOf68Q5nfgjydm5tCY0w6A6sRXor45mtE8sF0lmWOA1aGXmRQb3vvlPEfBF4kswupbaZ5X+fNjeICzL+ATJvQJlUBVkBbTHjh0r1m3XVQNDW0epVIrb/lB0bFx0Nz9HxbKgKhY+voeSAFEgouaEY+Go9EKp/hjtUv2H7bVH2LbM0n2OY9Tq8qrQb1lWh6Ctvc/oXkX/mRIpXmOkMqbFM+7tXqisXAJZPWLz5s0fTzF7e3sDRY/Vs+O8gxyixwVD1R0NEVyOyT13KNMvRB4cUWFlM7JsxNGjR5czSrBHbNu2LVAesvqduGYdvXqM8rMUFSJRHV1HzAnbv+l+7B+5FbUhS4hubm6Ym9Iv8uLj4zNs2DCgaNm3Pk0i5aI6u4AF0ugp1/NHMiu6SpzXjLLT7xRxsG7atClQtKTeVXr5W+pOR627e6hUfLHC8FXihIgp9kGDBokxCE9PzxEjRgDlIaqiEomdBZc702ggI9XwTk0k/lYvvviiuP9PREREixYtgPKQkmK+pFgFFotGzWsqqHpZK6+5+AEc35uedrf4QX5JkRKjLQy+EsMyvEb4qXXx+dIIk9at5yRCA17n+pfGGTCcwOJTQDyB0SoN3zX0o5J6aiknWTUrjuWEZ4lPEW+ubQkMB49+K11EAco0K/0l8bdkGamUdXBhgxo6dOhr9DVplJryhEL8fV3q3esFqiKelbBoPrMyVu4o5XlRVYK4RH8D1aIR45QPZQQaIYBaJo6lpbSV9iE2kJWNdelinbpjbUsDQVBxQ8lyJyUSDgcFdbE6K1WVlph97mC23J5r0talUzRVJCnUWIj7vk+Nu6zgpIyzl1NgpEV+kHwxf/dy+sVjOZdP5LR61q19bypHEyH0IxXUva2ZEL95+w4OtSEt/Z28zFO6tE5gZExIa2GJYHpc3tmDWVdPKca8Z6I5JjYOmkssGM7kVddZSb6uXPHGLWcvxyZdgi1ahfp4h7lEdg9lOO6rN2s7Y8pEMGC+Qtp1AANQUUa5WkLMTS/ZsTo5olv9gAgrHMXqt/X3a+L91QwL0KIgQmvbBrOUqoV468KDTUsTInuEshxYKx5BjqGtA1cSr0Wet2wdCj1iBT161ULcv/5eeDsTTUozIw7uUq8Qt6/figOK0dAG9AxfqkKIq+fEO/s6y5ystzPUwzfcjZNxm5cmArEw2hCYxcJDhTZuZUI8/EtmiUoT3NwLbIaGHYKy7helxBcDkWhtRAsenJ/QWbl8PNs7tMZ7P1k6Du52u7+p7fo3IyHYiJZsJGqzEIa7xAqFeGJ3FmZNvOu7ApGcv/TXjLlPKwqyoa4Ja+OP6crcDBJ3ixYSm2Bqogf12LCxzirIV7QioEIhXj6Va+dsJfHCmiKVS/78obYrj4zBE3jN770/e+++nUAG5VbM6FOhEJUFav9GHmCTuPo4Z9wn1EysKdevXwVLwHCK78aZAomEtXcx1mz0+LsX/zj0XWLSVSdH96aNn+nVdaydnSOejzn5859H1k4cs2rDlrdT0+L8fcM7dxjWtnVf8Vl7fv8y9sJeucyhVfPnfLyMuN7Wt4FrZpKJSqUbla7d2+DPj5d9sOrr5bt3HgZhk8Mj6zesTrh7x9XVLTy88bSpb/n6lu5tVsklERxVt23/cf/+PYlJCSHB9du0aT/m1Yn6q/qrRY285luX8sFoYYKMzMRv1k1VqYqmjPvu5eFLUlJvrlo7Ua0WZnRxEmlhYf6O35a9GP3Ox++fbB7V7acdC7Nz7uOl46e3HT/9y6A+M6eN/97TPeDPQ2vAaLAyFqMkN84owML5fa9QH2zmjLmiCmPPnpq3YGavXn1+2rJ3/tyPUlNTPvviI7FlJZd0bN++5YdNa4cMHr5l855+/Qb/tnfHlq01K6ZaY69ZkVsikRprzuy5C79LOOkrw5b4eof6+YQNHTAnOeX65X+PiFfValXPrmND6jVjGKZNyz74LUxOuYHnj534qXlkd0rPGUQAAAcYSURBVJSmg4ML9pHhYW3AmHASNv0ecaNzLZ2Vtd+v6typGyoJ+7zIyOaTJr5x8uSxa9qxu5JLOi5cPNe4ccRzz/V1c3Pv22fgyhXrnm7XEWpCjW3EElX5ta51CI7L9YIiHB1LA0Me7v6eHkF3Es7rGgQHRooHDvbCKqFCZT7KMSMr0denvq5NUEATMCoaXqEgToi1TPHFxd1s0iRS97BxI2Enm2vXrlR+SUdUVIuzZ08t/fj93/fvzs3LDQwICg9vBHWEYRuRYTTGC1cVKhWJyVcx+KJ/Mi8/U+/Vy38HlEUFGo1aLnfQnZHJ7MGoMAzHGmtMqAVPvo+9QqEoKiqSyx+tvXJwEP6eDx4UVHJJ/w7YXzo4OMYcP7Jk6XsSiaRLl57j//d/Xl51s+rcsBClMgkDxgqkOTt71g9p+Vy3MlXnHB0rC1jayR1ZllOplLozRcUPwJhgH2xnT15iU3+2eg2xsxN0plQ+WrtUoNWZp4dXJZf078CyLI7I+C8+Pu7cudPrNqwuKFB8uHA5VBtGexeDlwwL0c1TmpFirIEpwLfh2Qt7w0JbsQ/f0/20OG/Pyrxg7Abc3fzj71569qFN8u/1GDAmGg3vV9/Ine4TUIuhGfuwxo2aXrnyaBsl8TisQcNKLunfAf3lRo2a1q/fIDQ0DP/lK/J/2/sr1BBeY7hMjmF5NmjhpFZVUFen1mBERqPR7Nq3vLhYmZaesGf/ik9WDE9JvVX5s1pE9bh09RAmVPD44N8bEpIug9EoVqjRRgxv4QCEwbA1s9zlcrm3t09s7Ml/zseWlJQMjH7pWMzhbdt+zMvPwzNfrfq0dau2DcOFfbEruaTjwMHf0bM+fvwoGojoyvx97GBUZM3WWFbirBjuEes3c8Bn5GcUORthMja6vTOmbD7098bPvn45LT0+OChyaPScKp2PHs++WlCQvWPvJz/8NAdH9v4vTN/88zwjVZBKu5MtlZM44YjX1LhHHDF8zPfrvj595viPm/dgdCY9I23rzxtXfPUJxgjbPNX+f2OniM0quaTjzTfeXbFy2Zy5b+Cxh4cnjtFDh4yEOqLCamDr3ktQ81yDp/3B9rh+JNE3RB49kbjffdWs24Hh9l1fCgDLZN2CWwMnBAY1NmDzVOgYtuzsWqQoAptEWaSKnkDiN1CII1r6opUKFFfhKr6WXd1O7MtK/jczsKnhdSo5uanLVgw3eMle7lRYZDgt4ecdNmVcXe5b8e6i7hVdwmwNxxn4BUODm48dVaGvd+tkiqu7DIj8uPmKZ69YBEKpT77my0nb9vI49XuFQnR28nxj0kaDl9ALkckM1wpi2TquyFjRexDehqpIJjVg40q4ynLoynzlhI/CgUwsfOWUWPvD4KXKZNGmh9uV47nxsfdD2/g9fhU7Gw938xsrdfsebvydWK+ho4Tg0oMV9SiWThXJg5fnhRTmKXNSjBs9JoSki+kcBwPI81EewQDLWHCvWFq1yBBVZ7EmLmmQdCUNrJ17VzIVmQ9e+yAUSMbyl5NCTWdo6zeZuLTB5T/vZN+z2n4x8RKqUDFhaRhQjMmTrFnRBwesKZ+G37uaGneGxAn0teT634kPshXjFlMVmgK+lrVvkMmfhIOm5NrhhPs3637JklmI/yftyoF4VzfJeKpCk1DJAvuaBVPGLAg9vT/nn8NZWYm59i523g08nNwtp7j9Q7KTC7IScpWFxVIZO3BcvYBGFvMrsKxlx7MFKnj/NY7qtXvODf/F/pVzOSY3/mwyywqz6vGvI5FxGp7X7UCkvwmMiLY+J1Om6ib/qBLKoz1qHhoSYrVP7QRdXns7/WZlGoD+PjMsD5ryRT5ZjufVwhsqKS6d2+bqKesxLDAkwsIKo2s0Fh3P1lInPaIODDHiPzy4df7BrQv5ORnFmhK+WKknRAnwJY9es7QULGqT1UqyVCaPlMiyQqVvsdyr0JgREvwPTwrnxdlD4pmH9xceimvOdbtwMRzwQvnk0odie4mUYTjG3knq4i6J/I9rQAMbXSZLMrXNc4S3dMB/QKHUDkI3haQYRCrjJFILLoglkWBE3vD7p0K0JKR2TNEDY01YNgFoQwWFGXYNLXj3GBsktKlz5n1LnZt3fFeG3J6DCjp0KkRL4tnBHviBHdxskRnXhCt53Yb6VHSVrP2aKdVhw8K7DMu26uIVEmkB4SdFDn/ur/SEa/kvvxvq6FqhgUuFaJH8/FlyZkqRRs3r7/BdbmmSbtulcmh3DmfKPansOtWHd9LF1ype9SQ20QVuHzXUvjzLCRVu7R0lz4/29wurLHFAhWjJFENhod7y84fRWu2x9gz/WOgfym3lVaogntUrqqCTlbBTWNlEgnhG3MZeVw3koZi1yQNdpFd7nuPsnaA6UCFSiICGbyhEQIVIIQIqRAoRUCFSiIAKkUIEVIgUIvh/AAAA//8K91KcAAAABklEQVQDAAPvFDLgENXIAAAAAElFTkSuQmCC",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize our agent\n",
    "try:\n",
    "    from IPython.display import display, Image\n",
    "    display(Image(agent.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Could not display graph image: {e}\")\n",
    "    print(\"\\nGraph structure (ASCII):\")\n",
    "    print(agent.get_graph().draw_ascii())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cell-22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing our from-scratch agent:\n",
      "==================================================\n",
      "\n",
      "Conversation:\n",
      "  [HumanMessage]: What is 25 * 48? and what is the time?\n",
      "  [AIMessage]: [Tool calls: [{'name': 'calculate', 'args': {'expression': '25 * 48'}, 'id': 'call_KNtSBlduBTbLXKOzLMidYqyZ', 'type': 'tool_call'}, {'name': 'get_current_time', 'args': {}, 'id': 'call_v6YPP7J8BwTb8b4\n",
      "  [ToolMessage]: The result of 25 * 48 is 1200\n",
      "  [ToolMessage]: The current date and time is: 2026-01-24 17:34:13\n",
      "  [AIMessage]: The result of 25 * 48 is 1200.  \n",
      "The current date and time is: January 24, 2026, 17:34:13.\n"
     ]
    }
   ],
   "source": [
    "# Test our agent!\n",
    "print(\"Testing our from-scratch agent:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "response = agent.invoke({\"messages\": [HumanMessage(content=\"What is 25 * 48? and what is the time?\")]})\n",
    "\n",
    "print(\"\\nConversation:\")\n",
    "for msg in response[\"messages\"]:\n",
    "    msg_type = type(msg).__name__\n",
    "    content = msg.content if msg.content else f\"[Tool calls: {msg.tool_calls}]\" if hasattr(msg, 'tool_calls') and msg.tool_calls else \"[No content]\"\n",
    "    print(f\"  [{msg_type}]: {content[:200]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64e1eb0",
   "metadata": {},
   "source": [
    "A Note about OS versoins and compatbility\n",
    "Due to my MacOSX v 12 I was unable to support any model that supported noative tool calls locally..  I couldnt install the desired model\n",
    "\n",
    "`\n",
    "Trogdor:AIE9 dereky$ ollama pull gpt-oss:20b\n",
    "pulling manifest \n",
    "Error: pull model manifest: 412: \n",
    "\n",
    "The model you are attempting to pull requires a newer version of Ollama.\n",
    "`\n",
    "\n",
    "I tried the latest supported  llama2 version but that didn't have the ability to call tools, actually none of them did. (See trace below)\n",
    "I had to use VertexAI workbench to work around this and code there.\n",
    "the resulting notebook was built on a Vertex Hosted Instance and ported back/\n",
    "\n",
    "\n",
    "\n",
    "ResponseError                             Traceback (most recent call last)\n",
    "Cell In[23], line 5\n",
    "      2 print(\"Testing our from-scratch agent:\")\n",
    "      3 print(\"=\" * 50)\n",
    "----> 5 response = agent.invoke({\"messages\": [HumanMessage(content=\"What is 25 * 48?\")]})\n",
    "      7 print(\"\\nConversation:\")\n",
    "      8 for msg in response[\"messages\"]:\n",
    "\n",
    "File ~/old/personal/code/ai-makerspace-code/AIE9/.venv/lib/python3.12/site-packages/langgraph/pregel/main.py:3071, in Pregel.invoke(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\n",
    "   3068 chunks: list[dict[str, Any] | Any] = []\n",
    "   3069 interrupts: list[Interrupt] = []\n",
    "-> 3071 for chunk in self.stream(\n",
    "   3072     input,\n",
    "   3073     config,\n",
    "   3074     context=context,\n",
    "   3075     stream_mode=[\"updates\", \"values\"]\n",
    "   3076     if stream_mode == \"values\"\n",
    "   3077     else stream_mode,\n",
    "   3078     print_mode=print_mode,\n",
    "   3079     output_keys=output_keys,\n",
    "   3080     interrupt_before=interrupt_before,\n",
    "   3081     interrupt_after=interrupt_after,\n",
    "   3082     durability=durability,\n",
    "   3083     **kwargs,\n",
    "...\n",
    "    181 for line in r.iter_lines():\n",
    "    182   part = json.loads(line)\n",
    "\n",
    "ResponseError: registry.ollama.ai/library/llama2:13b does not support tools (status code: 400)\n",
    "During task with name 'agent' and id '0fa67bc1-c9c6-410a-5ba4-a48ab03d34d0'\n",
    "Output is truncated. View as a scrollable element or open in a text editor. Adjust cell output settings..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cell-23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with multiple tool calls:\n",
      "==================================================\n",
      "\n",
      "Final response:\n",
      "The current time is 17:34. The result of 100 divided by the current hour (17) is approximately 5.88.\n"
     ]
    }
   ],
   "source": [
    "# Test with multiple tools\n",
    "print(\"Testing with multiple tool calls:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "response = agent.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"What time is it, and what is 100 divided by the current hour?\")]\n",
    "})\n",
    "\n",
    "print(\"\\nFinal response:\")\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cell-24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming agent execution:\n",
      "==================================================\n",
      "\n",
      "[Node: agent]\n",
      "  Tool calls: ['calculate']\n",
      "\n",
      "[Node: tools]\n",
      "  Content: The result of 200 * 0.15 is 30.0\n",
      "\n",
      "[Node: agent]\n",
      "  Content: 15% of 200 is 30.\n"
     ]
    }
   ],
   "source": [
    "# Stream the agent's execution to see it step by step\n",
    "print(\"Streaming agent execution:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for chunk in agent.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"Calculate 15% of 200\")]},\n",
    "    stream_mode=\"updates\"\n",
    "):\n",
    "    for node_name, values in chunk.items():\n",
    "        print(f\"\\n[Node: {node_name}]\")\n",
    "        if \"messages\" in values:\n",
    "            for msg in values[\"messages\"]:\n",
    "                if hasattr(msg, 'content') and msg.content:\n",
    "                    print(f\"  Content: {msg.content[:200]}\")\n",
    "                if hasattr(msg, 'tool_calls') and msg.tool_calls:\n",
    "                    print(f\"  Tool calls: {[tc['name'] for tc in msg.tool_calls]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "---\n",
    "## â“ Question #1:\n",
    "\n",
    "In our from-scratch agent, we defined a `should_continue` function that returns either `\"tools\"` or `\"end\"`. How does this compare to how `create_agent` handles the same decision? What additional logic might `create_agent` include that we didn't implement?\n",
    "\n",
    "##### Answer:\n",
    "\n",
    "###### create_agent inner workings\n",
    "create_agent has an internal \"agent loop\" which essentially does the same thing with some extras.  It will basically has these components and follows the actions.\n",
    "\n",
    "* Agent (planner/decider): the LLM + prompt + output parser that produces either:\n",
    "  * â€œcall tool X with args Yâ€, or\n",
    "  * â€œfinal answerâ€\n",
    "* Executor / Runner: the loop that:\n",
    "  * feeds observations back to the agent,\n",
    "  * runs tools,\n",
    "  * enforces limits (max iterations, timeouts),\n",
    "  * handles errors\n",
    "\n",
    "###### create_agent compared to our should_continue\n",
    "create_agent had a tool loop and a 'complete' block.\n",
    "In both cases the LLM decided WHICH tool to call.\n",
    "In our case the should_continue logic was very simple\n",
    "\n",
    "> ```python\n",
    "> if we have a tool return it\n",
    "> ```\n",
    "> ```python\n",
    "> else return 'end'\n",
    "> ```\n",
    "\n",
    "\n",
    "That code is placed as a conditional_edge between the agent and either a tool call or the END of the DAG\n",
    "\n",
    "The additional logic in create_agent is detailed below.  Basically a lot of the blocking and tackling of errors, timeouts, loops, etc are covered by the framework so we dont have to worry about them.\n",
    "\n",
    "###### create_agent additional logic\n",
    "create_agent has some built in additional logic that we don't have to implement:\n",
    "* max_iterations - it will stop if a condition is met where the agent is looping\n",
    "* max_execution_time - after a max time it will stop and return, preventing overly long running tasks\n",
    "* parsing-error recovery - if the model outputs malformed JSON or invalid tool args the error will be caught and either retry the LLM with messaging to try to fix or have the model treat this as an observation and the model will try to correct the error\n",
    "* tool exception handling - if a tool returns an exception, the model will treat the error as an observation and may retry the tool call\n",
    "* Multi-tool calls per turn - the tool calling infrastructure can emit several tool calls at once and feed all the results back to the model and re-query the model.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": [
    "## â“ Question #2:\n",
    "\n",
    "We used `ToolNode` from `langgraph.prebuilt` to execute tools. Looking at the tool execution flow, what would happen if we wanted to add logging, error handling, or rate limiting to tool execution? How would building our own tool node give us more control?\n",
    "\n",
    "##### Answer:\n",
    "\n",
    "ToolNode standardizes â€œtake the modelâ€™s tool calls â†’ run them â†’ write tool results back into state.â€ \n",
    "At a high level, ToolNode does something like:\n",
    "* Read the most recent assistant message from state\n",
    "* Extract tool_calls\n",
    "* For each tool call:\n",
    "  * find the matching tool by name\n",
    "  * execute it with args\n",
    "  * package the result as a ToolMessage\n",
    "  * Append those tool result messages back into the conversation state\n",
    "\n",
    "We have an issue if we want to add logging, error handling or rate-limiting while using ToolNode. The problem is you can log around ToolNode but not inside it.  Any errors, issues, or timeouts etc would be opaque to us, and we're reliant on what ToolNode passes back. \n",
    "We would maybe write a wrapper around ToolNode to standardize it, but again you dont get the internals and you can't control timeouts from OUTSIDE of the ToolNode call you can only log.  \n",
    "The only way to enforce real changes would be a new replacement class for ToolNode like ToolNodeWithExtras or CustomToolNode.\n",
    "\n",
    "\n",
    "Inside of CustomToolNode we would then be able to: \n",
    "* emit logs per tool call\n",
    "* wraps tool executions in timeout + retry\n",
    "* implement a rate limiter\n",
    "* emits consistent error ToolMessages back to the LLM\n",
    "\n",
    "Ideally our CustomToolNode would take LOTS of configuration on how to implement these patterns.  Ideally you pass classes to handle the rate limiting, logging specs, the timeout and retry values, etc..  this makes sure we get what we want and can extend it over time.\n",
    "\n",
    "\n",
    "> ```python\n",
    "> CustomToolNode (\n",
    "    loggingSpec,\n",
    "    retrySpec,\n",
    "    rateLimiterSpec,\n",
    "    preToolHook,\n",
    "    postToolHook \n",
    "    )\n",
    "> ```\n",
    "and so on..\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-27",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ—ï¸ Activity #1: Implement a Custom Routing Function\n",
    "\n",
    "Extend the agent by implementing a **custom routing function** that adds more sophisticated logic.\n",
    "\n",
    "Ideas:\n",
    "- Add a maximum iteration limit to prevent infinite loops\n",
    "- Route to different nodes based on the type of tool being called\n",
    "- Add a \"thinking\" step before tool execution\n",
    "\n",
    "Requirements:\n",
    "1. Modify the `should_continue` function or create a new one\n",
    "2. Add any new nodes if needed\n",
    "3. Rebuild and test the agent\n",
    "\n",
    "**ðŸ“š Documentation:**\n",
    "- [Conditional Edges](https://langchain-ai.github.io/langgraph/concepts/low_level/#conditional-edges)\n",
    "- [How to create branches for parallel node execution](https://langchain-ai.github.io/langgraph/how-tos/branching/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cell-28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReAct agent built from scratch!\n"
     ]
    }
   ],
   "source": [
    "### YOUR CODE HERE ###\n",
    "# Here I added a \"thinking\" node that will be called if the LLM returns a tool call.\n",
    "# It will then return a message to the user that we are thinking about their problem.\n",
    "# Then the tool node will be called and the results will be added to the state.\n",
    "# The agent will then continue.\n",
    "# Initially I tried to push an AIMessage to the state but it was not working \n",
    "# openai.BadRequestError: Error code: 400 - {'error': {'message': \"An assistant message with 'tool_calls' must be followed by tool messages responding to each 'tool_call_id'. The following tool_call_ids did not have response messages: call_6XDApRWYDWXSJOfcNrgkXL3B, call_f96mDs51nNgNbIdxj6HyDFxX\", 'type': 'invalid_request_error', 'param': 'messages', 'code': None}}\n",
    "# something I wasn't aware that you can't push nodes back on that are AI nodes like this, so we just emit the message to the user here\n",
    "# Design decision to make the state machine simpler was to say if there are no tools there is no 'thinking' node.\n",
    "\n",
    "\n",
    "# Example: Add iteration tracking to prevent infinite loops\n",
    "class AgentStateWithCounter(TypedDict):\n",
    "    messages: Annotated[list[BaseMessage], add_messages]\n",
    "    iteration_count: int\n",
    "    thinking_done: bool\n",
    "\n",
    "def thinking_node(state: AgentStateWithCounter) -> str:\n",
    "    \"\"\"Produce some text that will be displayed to the user which repeats back what they asked for.\"\"\"\n",
    "    first_human_message = next(x for x in state['messages'] if isinstance(x, HumanMessage))\n",
    "    print(\"thinking about your problem... \"+first_human_message.content)\n",
    "    return {\n",
    "        \"thinking_done\": True\n",
    "    }\n",
    "    # \"messages\": [AIMessage(content=\"thinking about your problem...\"+first_human_message.content)]\n",
    "\n",
    "def custom_should_continue(state: AgentStateWithCounter) -> Literal[\"tools\", \"end\", \"thinking\"]:\n",
    "    \"\"\"Determine whether to call tools or end the conversation.\"\"\"\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    \n",
    "    # If the LLM made tool calls, route to tools node\n",
    "    # if we havent spit out the thinking message yet, do it, set a flag in state\n",
    "    # then next time we will be thinking_done and call the tool.\n",
    "    if state.get('thinking_done') and hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    elif not state.get('thinking_done') and hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
    "        return \"thinking\"\n",
    "    else:\n",
    "        return \"end\"\n",
    "# Build your custom agent\n",
    "# Step 7: Build the Graph!\n",
    "workflow2 = StateGraph(AgentStateWithCounter)\n",
    "\n",
    "# Add nodes\n",
    "workflow2.add_node(\"agent\", agent_node)\n",
    "workflow2.add_node(\"thinking\", thinking_node)\n",
    "workflow2.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Set the entry point\n",
    "workflow2.add_edge(START, \"agent\")\n",
    "\n",
    "# Add conditional edge from agent\n",
    "workflow2.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    custom_should_continue,\n",
    "    {\n",
    "        \"tools\": \"tools\",  # If should_continue returns \"tools\", go to tools node\n",
    "        \"thinking\": \"thinking\", # If should_continue returns \"thinking\", go to thinking node\n",
    "        \"end\": END         # If should_continue returns \"end\", finish\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add edge from tools back to agent (the loop!)\n",
    "workflow2.add_edge(\"thinking\", \"tools\")\n",
    "workflow2.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "# Compile the graph\n",
    "agent2 = workflow2.compile()\n",
    "\n",
    "print(\"ReAct agent built from scratch!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1e44e042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the RAG agent\n",
    "try:\n",
    "    from IPython.display import display, Image\n",
    "    display(Image(agent2.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Could not display graph image: {e}\")\n",
    "    print(\"\\nGraph structure:\")\n",
    "    print(agent2.get_graph().draw_ascii())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cell-29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with custom_should_continue:\n",
      "==================================================\n",
      "thinking about your problem... What time is it,  return the square root of 100?\n",
      "\n",
      "Final response:\n",
      "The current time is 17:49:14. The square root of 100 is 10.\n"
     ]
    }
   ],
   "source": [
    "# Test your custom agent\n",
    "# Test with multiple tools\n",
    "print(\"Testing with custom_should_continue:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "response = agent2.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"What time is it,  return the square root of 100?\")]\n",
    "})\n",
    "\n",
    "print(\"\\nFinal response:\")\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-30",
   "metadata": {},
   "source": [
    "---\n",
    "# Breakout Room #2\n",
    "## Agentic RAG with Local Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-31",
   "metadata": {},
   "source": [
    "Now let's build a full **Agentic RAG** system from scratch using our local models!\n",
    "\n",
    "We'll transition from the `aimakerspace` utilities to the **LangChain ecosystem**:\n",
    "\n",
    "| Task | aimakerspace | LangChain |\n",
    "|------|--------------|----------|\n",
    "| Load Documents | `TextFileLoader` | `TextLoader` |\n",
    "| Split Text | `CharacterTextSplitter` | `RecursiveCharacterTextSplitter` |\n",
    "| Embeddings | Custom | `OllamaEmbeddings` |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-32",
   "metadata": {},
   "source": [
    "## Task 5: Loading & Chunking with LangChain\n",
    "\n",
    "Let's use LangChain's document loaders and text splitters.\n",
    "\n",
    "**ðŸ“š Documentation:**\n",
    "- [Document Loaders Conceptual Guide](https://python.langchain.com/docs/concepts/document_loaders/)\n",
    "- [TextLoader Reference](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.text.TextLoader.html)\n",
    "- [RecursiveCharacterTextSplitter](https://python.langchain.com/docs/how_to/recursive_text_splitter/)\n",
    "- [Text Splitters Conceptual Guide](https://python.langchain.com/docs/concepts/text_splitters/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cell-33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 document(s)\n",
      "Total characters: 16,206\n",
      "\n",
      "Document metadata: {'source': 'data/HealthWellnessGuide.txt'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Load the document using LangChain's TextLoader\n",
    "loader = TextLoader(\"data/HealthWellnessGuide.txt\")\n",
    "documents = loader.load()\n",
    "\n",
    "print(f\"Loaded {len(documents)} document(s)\")\n",
    "print(f\"Total characters: {sum(len(doc.page_content) for doc in documents):,}\")\n",
    "print(f\"\\nDocument metadata: {documents[0].metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cell-34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into 45 chunks\n",
      "\n",
      "Sample chunk (first 300 chars):\n",
      "--------------------------------------------------\n",
      "The Personal Wellness Guide\n",
      "A Comprehensive Resource for Health and Well-being\n",
      "\n",
      "PART 1: EXERCISE AND MOVEMENT\n",
      "\n",
      "Chapter 1: Understanding Exercise Basics\n",
      "\n",
      "Exercise is one of the most important things you can do for your health. Regular physical activity can improve your brain health, help manage weigh...\n"
     ]
    }
   ],
   "source": [
    "# Split documents using RecursiveCharacterTextSplitter\n",
    "# This is more sophisticated than simple character splitting!\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100,\n",
    "    length_function=len,\n",
    "    # Default separators: [\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    # Tries to keep paragraphs, then sentences, then words together\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"Split into {len(chunks)} chunks\")\n",
    "print(f\"\\nSample chunk (first 300 chars):\")\n",
    "print(\"-\" * 50)\n",
    "print(chunks[0].page_content[:300] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-35",
   "metadata": {},
   "source": [
    "## Task 6: Setting up Qdrant with Local Embeddings\n",
    "\n",
    "Now we'll use **OllamaEmbeddings** with the `embeddinggemma` model - completely local!\n",
    "\n",
    "**ðŸ“š Documentation:**\n",
    "- [OllamaEmbeddings Reference](https://python.langchain.com/api_reference/ollama/embeddings/langchain_ollama.embeddings.OllamaEmbeddings.html)\n",
    "- [Qdrant Vector Store Integration](https://python.langchain.com/docs/integrations/vectorstores/qdrant/)\n",
    "- [Embedding Models Conceptual Guide](https://python.langchain.com/docs/concepts/embedding_models/)\n",
    "- [EmbeddingGemma Overview (Google)](https://ai.google.dev/gemma/docs/embeddinggemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cell-36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimension: 768\n",
      "Using local model: embeddinggemma\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "\n",
    "# Initialize local embedding model\n",
    "embedding_model = OllamaEmbeddings(model=\"embeddinggemma\")\n",
    "#embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "# here still using the embeddinggemma model for embeddings\n",
    "# just needed to do 'ollama serve' to start the embedding model locally\n",
    "\n",
    "# Get embedding dimension\n",
    "sample_embedding = embedding_model.embed_query(\"test\")\n",
    "embedding_dim = len(sample_embedding)\n",
    "print(f\"Embedding dimension: {embedding_dim}\")\n",
    "print(f\"Using local model: embeddinggemma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cell-37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created collection: wellness_knowledge_base_local\n"
     ]
    }
   ],
   "source": [
    "# Create Qdrant client (in-memory for development)\n",
    "qdrant_client = QdrantClient(\":memory:\")\n",
    "\n",
    "# Create a collection for our wellness documents\n",
    "collection_name = \"wellness_knowledge_base_local\"\n",
    "\n",
    "qdrant_client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=VectorParams(\n",
    "        size=embedding_dim,\n",
    "        distance=Distance.COSINE\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"Created collection: {collection_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cell-38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding documents to vector store (this may take a moment with local embeddings)...\n",
      "Added 45 documents to vector store\n"
     ]
    }
   ],
   "source": [
    "# Create vector store and add documents\n",
    "vector_store = QdrantVectorStore(\n",
    "    client=qdrant_client,\n",
    "    collection_name=collection_name,\n",
    "    embedding=embedding_model\n",
    ")\n",
    "\n",
    "# Add documents to the vector store\n",
    "print(\"Adding documents to vector store (this may take a moment with local embeddings)...\")\n",
    "vector_store.add_documents(chunks)\n",
    "print(f\"Added {len(chunks)} documents to vector store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cell-39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved documents:\n",
      "\n",
      "--- Document 1 ---\n",
      "Chapter 3: Building a Workout Routine\n",
      "\n",
      "Starting a new exercise routine can feel overwhelming. The key is to start slowly and gradually increase intensity and duration over time....\n",
      "\n",
      "--- Document 2 ---\n",
      "Adults typically need 7-9 hours of sleep per night. Sleep occurs in cycles of about 90 minutes, alternating between REM (rapid eye movement) and non-REM sleep.\n",
      "\n",
      "The four stages of sleep:\n",
      "- Stage 1: Li...\n",
      "\n",
      "--- Document 3 ---\n",
      "- Chin Tucks: While sitting or standing tall, pull your chin back to create a \"double chin.\" Hold for 5 seconds, repeat 10 times....\n"
     ]
    }
   ],
   "source": [
    "# Test the retriever\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "test_results = retriever.invoke(\"How can I improve my sleep?\")\n",
    "\n",
    "print(\"Retrieved documents:\")\n",
    "for i, doc in enumerate(test_results, 1):\n",
    "    print(f\"\\n--- Document {i} ---\")\n",
    "    print(doc.page_content[:200] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-40",
   "metadata": {},
   "source": [
    "## Task 7: Creating a RAG Tool\n",
    "\n",
    "Now let's wrap our retriever as a tool that the agent can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cell-41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG tool created: search_wellness_knowledge\n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "def search_wellness_knowledge(query: str) -> str:\n",
    "    \"\"\"Search the wellness knowledge base for information about health, fitness, nutrition, sleep, and mental wellness.\n",
    "    \n",
    "    Use this tool when the user asks questions about:\n",
    "    - Physical health and fitness\n",
    "    - Nutrition and diet\n",
    "    - Sleep and rest\n",
    "    - Mental health and stress management\n",
    "    - General wellness tips\n",
    "    \n",
    "    Args:\n",
    "        query: The search query to find relevant wellness information\n",
    "    \"\"\"\n",
    "    results = retriever.invoke(query)\n",
    "    \n",
    "    if not results:\n",
    "        return \"No relevant information found in the wellness knowledge base.\"\n",
    "    \n",
    "    # Format the results\n",
    "    formatted_results = []\n",
    "    for i, doc in enumerate(results, 1):\n",
    "        formatted_results.append(f\"[Source {i}]:\\n{doc.page_content}\")\n",
    "    \n",
    "    return \"\\n\\n\".join(formatted_results)\n",
    "\n",
    "print(f\"RAG tool created: {search_wellness_knowledge.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-42",
   "metadata": {},
   "source": [
    "## Task 8: Building Agentic RAG from Scratch\n",
    "\n",
    "Now let's put it all together - a complete agentic RAG system built from scratch!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cell-43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tools for RAG agent:\n",
      "  - search_wellness_knowledge\n",
      "  - calculate\n",
      "  - get_current_time\n",
      "  - return_sqrt\n"
     ]
    }
   ],
   "source": [
    "# Define all tools for our RAG agent\n",
    "rag_tools = [search_wellness_knowledge, calculate, get_current_time, return_sqrt]\n",
    "\n",
    "# Bind tools to the LLM\n",
    "rag_llm_with_tools = llm.bind_tools(rag_tools)\n",
    "\n",
    "print(\"Tools for RAG agent:\")\n",
    "for t in rag_tools:\n",
    "    print(f\"  - {t.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cell-44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG agent node defined\n"
     ]
    }
   ],
   "source": [
    "# Define the RAG agent components\n",
    "RAG_SYSTEM_PROMPT = \"\"\"You are a helpful wellness assistant with access to a comprehensive health and wellness knowledge base.\n",
    "\n",
    "Your role is to:\n",
    "1. Answer questions about health, fitness, nutrition, sleep, and mental wellness\n",
    "2. ALWAYS search the knowledge base when the user asks wellness-related questions\n",
    "3. Provide accurate, helpful information based on the retrieved context\n",
    "4. Be supportive and encouraging in your responses\n",
    "5. If you cannot find relevant information, say so honestly\n",
    "\n",
    "Remember: Always cite information from the knowledge base when applicable.\"\"\"\n",
    "\n",
    "def rag_agent_node(state: AgentState):\n",
    "    \"\"\"The RAG agent node - calls the LLM with wellness system prompt.\"\"\"\n",
    "    messages = [SystemMessage(content=RAG_SYSTEM_PROMPT)] + state[\"messages\"]\n",
    "    response = rag_llm_with_tools.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# Create tool node for RAG tools\n",
    "rag_tool_node = ToolNode(rag_tools)\n",
    "\n",
    "print(\"RAG agent node defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cell-45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agentic RAG built from scratch\n"
     ]
    }
   ],
   "source": [
    "# Build the RAG agent graph\n",
    "rag_workflow = StateGraph(AgentState)\n",
    "\n",
    "# Add nodes\n",
    "rag_workflow.add_node(\"agent\", rag_agent_node)\n",
    "rag_workflow.add_node(\"tools\", rag_tool_node)\n",
    "\n",
    "# Set entry point\n",
    "rag_workflow.add_edge(START, \"agent\")\n",
    "\n",
    "# Add conditional edge\n",
    "rag_workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    {\"tools\": \"tools\", \"end\": END}\n",
    ")\n",
    "\n",
    "# Add edge from tools back to agent\n",
    "rag_workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "# Compile\n",
    "rag_agent = rag_workflow.compile()\n",
    "\n",
    "print(\"Agentic RAG built from scratch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cell-46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the RAG agent\n",
    "try:\n",
    "    from IPython.display import display, Image\n",
    "    display(Image(rag_agent.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Could not display graph image: {e}\")\n",
    "    print(\"\\nGraph structure:\")\n",
    "    print(rag_agent.get_graph().draw_ascii())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cell-47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Agentic RAG (with local models):\n",
      "==================================================\n",
      "\n",
      "Final Response:\n",
      "==================================================\n",
      "Here are some effective tips for better sleep:\n",
      "\n",
      "1. **Consistent Sleep Schedule**: Try to go to bed and wake up at the same time each day, even on weekends. This helps regulate your body's internal clock.\n",
      "\n",
      "2. **Relaxing Bedtime Routine**: Establish a calming pre-sleep routine, such as reading, gentle stretching, or taking a warm bath. This signals your body that it's time to wind down.\n",
      "\n",
      "3. **Ideal Sleep Environment**: Keep your bedroom cool, dark, and quiet. Consider blackout curtains, eye masks, or white noise machines if needed.\n",
      "\n",
      "4. **Limit Screen Exposure**: Reduce screen time at least 1-2 hours before bed. The blue light emitted by screens can interfere with your ability to fall asleep.\n",
      "\n",
      "5. **Monitor Caffeine Intake**: Avoid consuming caffeine in the afternoon and evening, preferably after 2 PM, as it can disrupt sleep.\n",
      "\n",
      "6. **Regular Exercise**: Engage in regular physical activity, but try not to exercise too close to bedtime, as it may energize you and make it harder to fall asleep.\n",
      "\n",
      "7. **Mind Your Meals**: Avoid heavy meals, alcohol, and snacks close to bedtime.\n",
      "\n",
      "Implementing these tips can help improve the quality of your sleep, leading to a more rested and rejuvenated feeling upon waking. Sweet dreams! ðŸŒ™âœ¨\n"
     ]
    }
   ],
   "source": [
    "# Test the RAG agent\n",
    "print(\"Testing Agentic RAG (with local models):\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "response = rag_agent.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"What are some tips for better sleep?\")]\n",
    "})\n",
    "\n",
    "print(\"\\nFinal Response:\")\n",
    "print(\"=\" * 50)\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cell-48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with complex query:\n",
      "==================================================\n",
      "\n",
      "Final Response:\n",
      "==================================================\n",
      "It sounds like youâ€™re going through a tough time with stress and sleep issues. Here are some suggestions that can help:\n",
      "\n",
      "1. **Stress Management Techniques**:\n",
      "   - **Exercise**: Physical activity can be a great stress reliever. Even a short walk can help lift your mood.\n",
      "   - **Mindfulness and Meditation**: Practicing mindfulness or meditation can help calm your mind and reduce stress.\n",
      "   - **Deep Breathing Exercises**: Take slow, deep breaths to help lower stress levels.\n",
      "   - **Talk it Out**: Sometimes, talking to a friend or a mental health professional can relieve some stress.\n",
      "\n",
      "2. **Improving Sleep Quality**:\n",
      "   - **Establish a Sleep Routine**: Go to bed and wake up at the same time every day to regulate your body's clock.\n",
      "   - **Create a Relaxing Environment**: Make sure your sleeping area is quiet, dark, and cool, and avoid screens before bedtime.\n",
      "   - **Limit Caffeine and Heavy Meals Before Sleep**: Avoid consuming caffeine and heavy foods a few hours before bedtime.\n",
      "   - **Consider Relaxation Techniques**: Try relaxing activities before bed, such as reading or taking a warm bath.\n",
      "\n",
      "As for your sleep calculation, if you sleep 6 hours a night for a week, that totals **42 hours** of sleep. \n",
      "\n",
      "If you continue to struggle with stress or sleep issues, it might be helpful to consult a healthcare professional. You're not alone in this, and there are effective strategies to help improve your situation!\n"
     ]
    }
   ],
   "source": [
    "# Test with a complex query requiring both RAG and calculation\n",
    "print(\"Testing with complex query:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "response = rag_agent.invoke({\n",
    "    \"messages\": [HumanMessage(\n",
    "        content=\"I'm stressed and sleeping poorly. What should I do? Also, if I sleep 6 hours a night for a week, how many total hours is that?\"\n",
    "    )]\n",
    "})\n",
    "\n",
    "print(\"\\nFinal Response:\")\n",
    "print(\"=\" * 50)\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cell-49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing agent decision-making (should NOT use RAG):\n",
      "==================================================\n",
      "\n",
      "Final Response:\n",
      "The result of \\( 125 \\times 8 \\) is 1000. If you have any other questions or need help with wellness topics, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "# Test that the agent knows when NOT to use RAG\n",
    "print(\"Testing agent decision-making (should NOT use RAG):\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "response = rag_agent.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"What is 125 * 8?\")]\n",
    "})\n",
    "\n",
    "print(\"\\nFinal Response:\")\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-52",
   "metadata": {},
   "source": [
    "---\n",
    "## â“ Question #3:\n",
    "\n",
    "Compare the experience of building an agent from scratch with LangGraph versus using `create_agent` from Session 3. What are the trade-offs between control and convenience? When would you choose one approach over the other?\n",
    "\n",
    "##### Answer:\n",
    "\n",
    "###### Comparing Assignment 3 and 4.\n",
    "Building with LangGraph was more labor intensive, we had to make each node and edge explicitly AND define the exact graph AND bind the tools.  In our very small example it was more code, but not a crazy amount of code.  It reminded me a bit of using Airflow where you write Python to make a DAG of how you want things to interact.  You have a number of Operators to talk to Bigquery, Fivetran, Bash, python as the nodes, and you define the edges.  It was a definite time savings to use create_agent, but since we're in a class to learn how to do this, getting to LangGraph was important to understand one level down.\n",
    "\n",
    "###### Head To Head Comparison and Tradeoffs\n",
    "Overall LangGraph is a lower level graph framework.  We are making all the nodes and edges by hand which gives very fine grained control over interactions, but takes a deeper level of understanding of the workflow.  \n",
    "create_agent is more of an \"agent template\" where you simply register tools and let the framework take over.. there was no low level wiring of the nodes together, and no fine grained control.  \n",
    "\n",
    "When using LangGraph you get control over lower level details that you cannot get when using create_agent, like: \n",
    "* state storage or persistence\n",
    "* defining exact nodes in the graph (LLM Calls, tool calls, routing, validation, memory, retrieval)\n",
    "* defining exact edges in the graph ( routing, when to loop, when to stop, when to branch)\n",
    "* you have the ability for interrupts or human in the loop\n",
    "* you have control over explicit error handling at particular points in the flow\n",
    "* you have control over observability hooks for logging or monitoring\n",
    "\n",
    "create_agent gives you convenience at the expense of less control, you get:\n",
    "* ready to go agent loop\n",
    "* tool calling and message plumbing in place\n",
    "* defaults for how to format prompts, how tool results are injected and stop conditions\n",
    "\n",
    "The downside of LangGraph is its more code and work to get to the same point as create_agent.  \n",
    "The upside of LangGraph is more power.\n",
    "The upside of create_agent is a faster time to 'working' with less code and you don't need deeper understanding of the underlying concepts.\n",
    "\n",
    "\n",
    "###### When to Choose Each Approach\n",
    "\n",
    "####### Choose create agent when:\n",
    "* you are prototyping or showing high level agent concepts\n",
    "* the workflow is basic:  user input -> LLM think -> optional tool calls -> respond to user\n",
    "* you dont have specific guardrails and can accept system defaults\n",
    "* you want to move fast and test concepts outside of the LLM and just need something to be in place\n",
    "\n",
    "Its best for internal applications, simple RAG/Tool apps and Demo/teaching apps.\n",
    "\n",
    "####### Choose LangGraph when:\n",
    "* you have a very specific workflow, and don't want to rely on create_agent getting it right\n",
    "* you want to be able to audit or secure certain steps.  Or if you want fine-grained observability and debugging\n",
    "* you have hard boundaries to enforce (tool allow lists, budgets, data boundaries)\n",
    "* you are building a complex production system and want to start with a flexible and robust framework\n",
    "\n",
    "Its best for Production Apps with SLAs or complex workflows (multi-agent cases) and when you have interactions with systems that are risky (calling APIs to open tickets, trade stocks, etc..)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-53",
   "metadata": {},
   "source": [
    "## â“ Question #4:\n",
    "\n",
    "We used local models (gpt-oss:20b and embeddinggemma) instead of cloud APIs. What are the advantages and disadvantages of this approach? \n",
    "\n",
    "##### Answer:\n",
    "Advantages to Local\n",
    "* The local models were free (besides the compute needed on my laptop, which was already working)..  Yes our small amount of OpenAI Usage is minimal and under the free plan, but it could.  In a case with lots of usage, we would be able to purchase HW and then run it, so the cost structure is consistent and you can plan for it wit near-zero costs of incremental inference \n",
    "* The data never left my laptop.  So no PII or IP or regulated date was sent outside.  This data wasn't that sensitive, but in healthcare, legal, or other domains this would be crritical\n",
    "* Its easier to swap between models and vendors, download and use, vs signing usage agreeements, setting up credits, api keys..\n",
    "* If you want to customize heaviliy, you can do that.  Fine-tuning, LoRA etc can be done in any way you want\n",
    "* You can modify your inference pipelines or experiment with retrieval or reranking.\n",
    "* Latency is more consistent, since its inside of your infrastructure\n",
    "\n",
    "Disadvantages to Local\n",
    "* Since I don't have a GPU, it was Super slow\n",
    "* If you owned the HW (GPU, RAM, etc..), its a lot of up front $$, and you have to manage it on your own.\n",
    "* The OpenAI, Anthropic, Gemini foundation models are trained on TONS of data and are very strong for inference.  Open Source models are good but not as good.  \n",
    "* The large foundation models move quickly, have larger context windows, faster influence, in general better features/support\n",
    "* You'll need to handle any spikes in load if you're running locally\n",
    "\n",
    "\n",
    "Specifically for Embedding models they are almost always better locally since they are very cheap to run, deterministic, more private.  On the con-side they may have slightly weaker semantic quality and harder multi-lingual/niche-domain converage than their online equivaents.\n",
    "\n",
    "You can also do hybrid, Like I have to today due to MacOS12 issues, and run local embeddings and remote Foundation Model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-54",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ—ï¸ Activity #2: Extend the Agent with Memory\n",
    "\n",
    "LangGraph supports **checkpointing** which enables conversation memory across invocations.\n",
    "\n",
    "Your task: Add memory to the RAG agent so it can:\n",
    "1. Remember previous questions in the conversation\n",
    "2. Reference past context when answering new questions\n",
    "3. Build on previous answers\n",
    "\n",
    "Hint: Use `MemorySaver` from `langgraph.checkpoint.memory` and pass a `thread_id` in the config.\n",
    "\n",
    "**ðŸ“š Documentation:**\n",
    "- [LangGraph Persistence & Memory](https://langchain-ai.github.io/langgraph/concepts/persistence/)\n",
    "- [How to add memory to your graph](https://langchain-ai.github.io/langgraph/how-tos/persistence/)\n",
    "- [MemorySaver Reference](https://langchain-ai.github.io/langgraph/reference/checkpoints/#langgraph.checkpoint.memory.MemorySaver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cell-55",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "import uuid\n",
    "# Create a memory saver\n",
    "memory = MemorySaver()\n",
    "\n",
    "# Recompile the agent with checkpointing\n",
    "rag_agent_with_memory = rag_workflow.compile(checkpointer=memory)\n",
    "\n",
    "# Test with a conversation that requires memory\n",
    "# Use \n",
    "config = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cell-56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide the three numbers you'd like me to calculate!\n",
      "Please provide the other two numbers so I can add them up and take the square root of the sum!\n",
      "I still need one more number to complete the calculation. Please provide the third number!\n",
      "The sum of the numbers 50, 150, and 25 is 225, and the square root of that sum is 15.0. If you have any more questions or tasks, feel free to ask!\n",
      "The numbers youâ€™ve provided, listed in numerical order, are:\n",
      "\n",
      "1. 25\n",
      "2. 50\n",
      "3. 150\n",
      "\n",
      "If you have any more requests or questions, feel free to let me know!\n",
      "The first task you asked me to complete was to add three numbers together and take the square root of the sum. You provided the numbers 50, 150, and 25 for that calculation. If you have any more tasks or questions, just let me know!\n",
      "\n",
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "# Test your memory-enabled agent with a multi-turn conversation\n",
    "response = rag_agent_with_memory.invoke({\n",
    "    \"messages\": [\n",
    "        HumanMessage(\n",
    "        content=\"Im going to give you 3 numbers, add them up and take the square root of the sum.  \"\n",
    "    )\n",
    "    ]\n",
    "}, config=config)\n",
    "print(response[\"messages\"][-1].content)\n",
    "\n",
    "response2 = rag_agent_with_memory.invoke({\n",
    "    \"messages\": [\n",
    "            HumanMessage(\n",
    "        content=\"50\"\n",
    "            )\n",
    "    ]\n",
    "}, config=config)\n",
    "print(response2[\"messages\"][-1].content)\n",
    "\n",
    "response3 = rag_agent_with_memory.invoke({\n",
    "    \"messages\": [\n",
    "            HumanMessage(\n",
    "        content=\"150\"\n",
    "            )\n",
    "    ]\n",
    "}, config=config)\n",
    "print(response3[\"messages\"][-1].content)\n",
    "\n",
    "response4 = rag_agent_with_memory.invoke({\n",
    "    \"messages\": [\n",
    "            HumanMessage(\n",
    "        content=\"25\"\n",
    "            )\n",
    "    ]\n",
    "}, config=config)\n",
    "print(response4[\"messages\"][-1].content)\n",
    "\n",
    "response5 = rag_agent_with_memory.invoke({\n",
    "    \"messages\": [\n",
    "            HumanMessage(\n",
    "        content=\"ok now can you list all the numbers you have been given in numerical order?\"\n",
    "            )\n",
    "    ]\n",
    "}, config=config)\n",
    "print(response5[\"messages\"][-1].content)\n",
    "\n",
    "response6 = rag_agent_with_memory.invoke({\n",
    "    \"messages\": [\n",
    "            HumanMessage(\n",
    "        content=\"ok what was the first task i asked you to complete?\"\n",
    "            )\n",
    "    ]\n",
    "}, config=config)\n",
    "print(response6[\"messages\"][-1].content)\n",
    "\n",
    "\n",
    "print(\"\\nDONE!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8ae718",
   "metadata": {},
   "source": [
    "HW: Thoughts\n",
    "* it was pretty straightforward to give this Agent Memory, works quite well\n",
    "* it can accomplish a task that takes multiple turns, when the task is given first\n",
    "* it also can recall the numbers it's been given and re-order them as well, which shows it can access the memory as well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-57",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "In this session, we:\n",
    "\n",
    "1. **Built agents from scratch** using LangGraph's low-level primitives (StateGraph, nodes, edges)\n",
    "2. **Used local open-source models** with Ollama (gpt-oss:20b + embeddinggemma)\n",
    "3. **Transitioned to LangChain** for document loading and text splitting\n",
    "4. **Created an Agentic RAG system** that intelligently decides when to retrieve information\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "- **StateGraph** gives you full control over agent architecture\n",
    "- **Conditional edges** enable dynamic routing based on LLM decisions\n",
    "- **Local models** provide privacy and cost savings, with trade-offs in performance\n",
    "- **LangSmith** provides crucial visibility regardless of where your models run\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "Now that you understand the fundamentals, you can:\n",
    "- Add more sophisticated routing logic\n",
    "- Implement human-in-the-loop patterns\n",
    "- Build multi-agent systems\n",
    "- Deploy to production with LangGraph Platform\n",
    "\n",
    "**ðŸ“š Further Reading:**\n",
    "- [LangGraph How-To Guides](https://langchain-ai.github.io/langgraph/how-tos/)\n",
    "- [Human-in-the-Loop Patterns](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/)\n",
    "- [Multi-Agent Architectures](https://langchain-ai.github.io/langgraph/concepts/multi_agent/)\n",
    "- [LangGraph Platform](https://langchain-ai.github.io/langgraph/concepts/langgraph_platform/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
